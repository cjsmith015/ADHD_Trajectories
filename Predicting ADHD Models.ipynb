{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from impute_transform import ImputeTransform\n",
    "import model_metrics\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from fancyimpute import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('data/train_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_small = train_data.sample(n=400)\n",
    "#X = train_data_small.drop(columns=['DX','DXSUB'])\n",
    "#y = train_data_small['DX'].map({3:1, 1:0})\n",
    "#y_sub = train_data_small['DXSUB']\n",
    "X = train_data.drop(columns=['DX','DXSUB'])\n",
    "y = train_data['DX'].map({3:1, 1:0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['STOP_SSRTAVE_Y1', 'DPRIME1_Y1', 'DPRIME2_Y1', 'SSBK_NUMCOMPLETE_Y1',\n",
       "       'SSFD_NUMCOMPLETE_Y1', 'V_Y1', 'Y1_CLWRD_COND1', 'Y1_CLWRD_COND2',\n",
       "       'Y1_DIGITS_BKWD_RS', 'Y1_DIGITS_FRWD_RS', 'Y1_TRAILS_COND2',\n",
       "       'Y1_TRAILS_COND3', 'CW_RES', 'TR_RES', 'Y1_TAP_SD_TOT_CLOCK',\n",
       "       'Y1_P_TMCQ_ACTIVCONT', 'Y1_P_TMCQ_ACTIVITY', 'Y1_P_TMCQ_AFFIL',\n",
       "       'Y1_P_TMCQ_ANGER', 'Y1_P_TMCQ_FEAR', 'Y1_P_TMCQ_HIP',\n",
       "       'Y1_P_TMCQ_IMPULS', 'Y1_P_TMCQ_INHIBIT', 'Y1_P_TMCQ_SAD',\n",
       "       'Y1_P_TMCQ_SHY', 'Y1_P_TMCQ_SOOTHE', 'Y1_P_TMCQ_ASSERT',\n",
       "       'Y1_P_TMCQ_ATTFOCUS', 'Y1_P_TMCQ_LIP', 'Y1_P_TMCQ_PERCEPT',\n",
       "       'Y1_P_TMCQ_DISCOMF', 'Y1_P_TMCQ_OPENNESS', 'Y1_P_TMCQ_SURGENCY',\n",
       "       'Y1_P_TMCQ_EFFCONT', 'Y1_P_TMCQ_NEGAFFECT', 'DX', 'DXSUB'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data is acquired from the **ADHD Research Lab** at the Oregon Health and Science University. It contains 901 subjects from the first year of a longitudinal study. The data is de-identified. It has 35 features and two target variables.\n",
    "\n",
    "In this research project, I explore the differences in model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Model Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running cross-validation on four models: Logistic Regression, Random Forest, Gradient Boosting, and XGBoost, on four different sets of data:\n",
    " - All features, Target = DX\n",
    " - All features, Target = DXSUB\n",
    " - TMCQ features only, Target = DX\n",
    " - Neuropsych features only, Target = DX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_clf = make_pipeline(ImputeTransform(strategy=MatrixFactorization()),\n",
    "                        LogisticRegression(random_state=56))\n",
    "\n",
    "rf_clf = make_pipeline(ImputeTransform(strategy=MatrixFactorization()),\n",
    "                       RandomForestClassifier(n_jobs=-1, random_state=56))\n",
    "\n",
    "gb_clf = make_pipeline(ImputeTransform(strategy=MatrixFactorization()),\n",
    "                       GradientBoostingClassifier(random_state=56))\n",
    "\n",
    "xgb_clf = make_pipeline(ImputeTransform(strategy=MatrixFactorization()),\n",
    "                        XGBClassifier(max_depth=3, learning_rate=0.1,\n",
    "                        random_state=56))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scoring_list = ['accuracy', 'roc_auc', 'neg_log_loss']\n",
    "\n",
    "classifier_list = [log_reg_clf, rf_clf, gb_clf, xgb_clf]\n",
    "classifier_name = ['LogReg', 'RandomForest', 'GradientBoosting', 'XGB']\n",
    "\n",
    "metrics_of_interest = ['fit_time', 'score_time', 'test_accuracy',\n",
    "                       'test_neg_log_loss', 'test_roc_auc']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All Features, Target = DX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "metric_dx_df = model_metrics.get_metrics(X, y,\n",
    "                                classifier_list, classifier_name,\n",
    "                                scoring_list, metrics_of_interest,\n",
    "                                n_folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub_df = metric_dx_df[['test_accuracy','test_neg_log_loss', 'test_roc_auc']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_neg_log_loss</th>\n",
       "      <th>test_roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogReg</th>\n",
       "      <td>0.909</td>\n",
       "      <td>-0.205</td>\n",
       "      <td>0.972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>0.920</td>\n",
       "      <td>-0.436</td>\n",
       "      <td>0.962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoosting</th>\n",
       "      <td>0.937</td>\n",
       "      <td>-0.227</td>\n",
       "      <td>0.967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGB</th>\n",
       "      <td>0.919</td>\n",
       "      <td>-0.217</td>\n",
       "      <td>0.971</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  test_accuracy  test_neg_log_loss  test_roc_auc\n",
       "LogReg                    0.909             -0.205         0.972\n",
       "RandomForest              0.920             -0.436         0.962\n",
       "GradientBoosting          0.937             -0.227         0.967\n",
       "XGB                       0.919             -0.217         0.971"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df.astype(float).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_scores = metric_dx_df.loc['XGB',['test_accuracy','test_neg_log_loss', 'test_roc_auc']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.91880165289256188, -0.21653827447187718, 0.9712134502923977]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(log_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shape mismatch: objects cannot be broadcast to a single shape",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-f92f64700e8a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#_acc = metric_dx_df.loc['LogReg',['test_accuracy','test_neg_log_loss', 'test_roc_auc']]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mrects1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda2/envs/py36/lib/python3.6/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1708\u001b[0m                     warnings.warn(msg % (label_namer, func.__name__),\n\u001b[1;32m   1709\u001b[0m                                   RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1710\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1711\u001b[0m         \u001b[0mpre_doc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1712\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpre_doc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py36/lib/python3.6/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mbar\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2079\u001b[0m         x, height, width, y, linewidth = np.broadcast_arrays(\n\u001b[1;32m   2080\u001b[0m             \u001b[0;31m# Make args iterable too.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2081\u001b[0;31m             np.atleast_1d(x), height, width, y, linewidth)\n\u001b[0m\u001b[1;32m   2082\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2083\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0morientation\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'vertical'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py36/lib/python3.6/site-packages/numpy/lib/stride_tricks.py\u001b[0m in \u001b[0;36mbroadcast_arrays\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_m\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubok\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_m\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m     \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_broadcast_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py36/lib/python3.6/site-packages/numpy/lib/stride_tricks.py\u001b[0m in \u001b[0;36m_broadcast_shape\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;31m# use the old-iterator because np.nditer does not handle size 0 arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;31m# consistently\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m     \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m     \u001b[0;31m# unfortunately, it cannot handle 32 or more arguments directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mpos\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m31\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shape mismatch: objects cannot be broadcast to a single shape"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4AOAIQg+ABiC4AOAIf4NhPObPmHgVP0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbc15dc2f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "N = 4\n",
    "ind = np.arange(N)\n",
    "width = 0.3\n",
    "\n",
    "#_acc = metric_dx_df.loc['LogReg',['test_accuracy','test_neg_log_loss', 'test_roc_auc']]\n",
    "rects1 = ax.bar(ind, log_scores, width, color='r')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All Features, Target = DXSUB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics.scorer import make_scorer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "multiclass_roc = make_scorer(model_metrics.multiclass_roc_auc_score,\n",
    "                             greater_is_better=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log_reg_clf = make_pipeline(ImputeTransform(strategy=SimpleFill()),\n",
    "                        LogisticRegression(random_state=56))\n",
    "\n",
    "rf_clf = make_pipeline(ImputeTransform(strategy=SimpleFill()),\n",
    "                       RandomForestClassifier(n_jobs=-1, random_state=56))\n",
    "\n",
    "gb_clf = make_pipeline(ImputeTransform(strategy=SimpleFill()),\n",
    "                       GradientBoostingClassifier(random_state=56))\n",
    "\n",
    "xgb_clf = make_pipeline(ImputeTransform(strategy=SimpleFill()),\n",
    "                        XGBClassifier(max_depth=3, learning_rate=0.1,\n",
    "                        random_state=56))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_dict = {'accuracy': 'accuracy',\n",
    "                'log_loss': 'neg_log_loss',\n",
    "                'roc_auc': multiclass_roc}\n",
    "\n",
    "classifier_list = [log_reg_clf, rf_clf, gb_clf, xgb_clf]\n",
    "classifier_name = ['LogReg', 'RandomForest', 'GradientBoosting', 'XGB']\n",
    "\n",
    "metrics_of_interest = ['fit_time', 'score_time', 'test_accuracy',\n",
    "                       'test_neg_log_loss', 'test_roc_auc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scores = cross_validate(log_reg_clf, X, y_sub,\n",
    "                             scoring=scoring_dict,\n",
    "                             cv=2,\n",
    "                             return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CV on LogReg, RF, GB, XGB for:\n",
    "  - DX\n",
    "  - DXSUB\n",
    "  - TMCQ\n",
    "  - Neuropsych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizations, model selection, opinions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tune xgb for Dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Model Metrics Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_DX = train_data.drop(columns=['DX','DXSUB'])\n",
    "y_train_DX = train_data['DX']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_small, X_test_small, y_train_small, y_test_small = train_test_split(\n",
    "                    X_train_DX, y_train_DX, test_size=0.2, random_state=56)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logmod = LogisticRegression()\n",
    "logmod.fit(impute_data(X_train_small.values), y_train_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_prob_dx = logmod.predict_proba(impute_data(X_test_small.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prob_dx = logmod.predict(impute_data(X_test_small.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(pred_prob_dx[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_jitter(data, jitter=0.1):\n",
    "    return np.random.uniform(-jitter, jitter, size=data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,2))\n",
    "\n",
    "_ = ax.scatter(pred_prob_dx[:,0], make_jitter(pred_prob_dx[:,0]), c=np.vectorize(dx_dict.get)(y_test_small),\n",
    "           s=40, alpha=0.5)\n",
    "_ = ax.set_xlim(0,1)\n",
    "_ = ax.set_title('Predicted Probability of Positive vs Negative Classes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test_small, prob_dx, pos_label=3, drop_intermediate=False)\n",
    "roc_auc = auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(fpr, tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I created logistic regression, random forest, and gradient boosting models. I want to see the MSE and accuracy on train/test, cross-validated (k-fold=10), when predicting DX, and when predicting DXSUB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train_data = pd.read_csv('data/train_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%%capture\n",
    "#classifier_metrics = run_classifiers(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#with open('classifier_metrics.pkl', 'wb') as f:\n",
    "    #pickle.dump(classifier_metrics, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classification_metrics = pickle.load(open(\"classifier_metrics.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#[clf][pred][metric][train/test]\n",
    "# Logistic Regression\n",
    "lr_dx_mse_train = np.mean(classification_metrics[0][0][0][0])\n",
    "lr_dx_mse_test = np.mean(classification_metrics[0][0][0][1])\n",
    "lr_dx_acc_train = np.mean(classification_metrics[0][0][1][0])\n",
    "lr_dx_acc_test = np.mean(classification_metrics[0][0][1][1])\n",
    "\n",
    "lr_dxsub_mse_train = np.mean(classification_metrics[0][1][0][0])\n",
    "lr_dxsub_mse_test = np.mean(classification_metrics[0][1][0][1])\n",
    "lr_dxsub_acc_train = np.mean(classification_metrics[0][1][1][0])\n",
    "lr_dxsub_acc_test = np.mean(classification_metrics[0][1][1][1])\n",
    "\n",
    "# Random Forest\n",
    "rf_dx_mse_train = np.mean(classification_metrics[1][0][0][0])\n",
    "rf_dx_mse_test = np.mean(classification_metrics[1][0][0][1])\n",
    "rf_dx_acc_train = np.mean(classification_metrics[1][0][1][0])\n",
    "rf_dx_acc_test = np.mean(classification_metrics[1][0][1][1])\n",
    "\n",
    "rf_dxsub_mse_train = np.mean(classification_metrics[1][1][0][0])\n",
    "rf_dxsub_mse_test = np.mean(classification_metrics[1][1][0][1])\n",
    "rf_dxsub_acc_train = np.mean(classification_metrics[1][1][1][0])\n",
    "rf_dxsub_acc_test = np.mean(classification_metrics[1][1][1][1])\n",
    "\n",
    "# Gradient Boosting\n",
    "gb_dx_mse_train = np.mean(classification_metrics[2][0][0][0])\n",
    "gb_dx_mse_test = np.mean(classification_metrics[2][0][0][1])\n",
    "gb_dx_acc_train = np.mean(classification_metrics[2][0][1][0])\n",
    "gb_dx_acc_test = np.mean(classification_metrics[2][0][1][1])\n",
    "\n",
    "gb_dxsub_mse_train = np.mean(classification_metrics[2][1][0][0])\n",
    "gb_dxsub_mse_test = np.mean(classification_metrics[2][1][0][1])\n",
    "gb_dxsub_acc_train = np.mean(classification_metrics[2][1][1][0])\n",
    "gb_dxsub_acc_test = np.mean(classification_metrics[2][1][1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make dataframes\n",
    "metrics_dx_dict = {'DX_acc_train': [lr_dx_acc_train, rf_dx_acc_train, gb_dx_acc_train],\n",
    "                   'DX_acc_test': [lr_dx_acc_test, rf_dx_acc_test, gb_dx_acc_test],\n",
    "                   'DX_mse_train': [lr_dx_mse_train, rf_dx_mse_train, gb_dx_mse_train],\n",
    "                   'DX_mse_test': [lr_dx_mse_test, rf_dx_mse_test, gb_dx_mse_test]}\n",
    "\n",
    "metrics_DX = pd.DataFrame(data=metrics_dx_dict,\n",
    "                          columns=['DX_acc_train', 'DX_acc_test', 'DX_mse_train', 'DX_mse_test'],\n",
    "                          index=['LogReg', 'RandomForest', 'GradBoost'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metrics_dxsub_dict = {'DXSUB_acc_train': [lr_dxsub_acc_train, rf_dxsub_acc_train, gb_dxsub_acc_train],\n",
    "                   'DXSUB_acc_test': [lr_dxsub_acc_test, rf_dxsub_acc_test, gb_dxsub_acc_test],\n",
    "                   'DXSUB_mse_train': [lr_dxsub_mse_train, rf_dxsub_mse_train, gb_dxsub_mse_train],\n",
    "                   'DXSUB_mse_test': [lr_dxsub_mse_test, rf_dxsub_mse_test, gb_dxsub_mse_test]}\n",
    "\n",
    "metrics_DXSUB = pd.DataFrame(data=metrics_dxsub_dict,\n",
    "                             columns=['DXSUB_acc_train', 'DXSUB_acc_test', 'DXSUB_mse_train', 'DXSUB_mse_test'],\n",
    "                             index=['LogReg', 'RandomForest', 'GradBoost'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metrics_DX.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metrics_DXSUB.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neuropsych vs TMCQ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I've evaluated models on all the data, I want to check out what accuracy and mse looks like for models run JUST on neuropsych, and JUST on TMCQ.\n",
    "\n",
    "I'll use the same exact procedure as above, just with different X matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('data/train_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_TMCQ = train_data[['Y1_P_TMCQ_ACTIVCONT', 'Y1_P_TMCQ_ACTIVITY', 'Y1_P_TMCQ_AFFIL',\n",
    "       'Y1_P_TMCQ_ANGER', 'Y1_P_TMCQ_FEAR', 'Y1_P_TMCQ_HIP',\n",
    "       'Y1_P_TMCQ_IMPULS', 'Y1_P_TMCQ_INHIBIT', 'Y1_P_TMCQ_SAD',\n",
    "       'Y1_P_TMCQ_SHY', 'Y1_P_TMCQ_SOOTHE', 'Y1_P_TMCQ_ASSERT',\n",
    "       'Y1_P_TMCQ_ATTFOCUS', 'Y1_P_TMCQ_LIP', 'Y1_P_TMCQ_PERCEPT',\n",
    "       'Y1_P_TMCQ_DISCOMF', 'Y1_P_TMCQ_OPENNESS', 'Y1_P_TMCQ_SURGENCY',\n",
    "       'Y1_P_TMCQ_EFFCONT', 'Y1_P_TMCQ_NEGAFFECT']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_TMCQ.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_neuro = train_data[['STOP_SSRTAVE_Y1', 'DPRIME1_Y1', 'DPRIME2_Y1', 'SSBK_NUMCOMPLETE_Y1',\n",
    "       'SSFD_NUMCOMPLETE_Y1', 'V_Y1', 'Y1_CLWRD_COND1', 'Y1_CLWRD_COND2',\n",
    "       'Y1_DIGITS_BKWD_RS', 'Y1_DIGITS_FRWD_RS', 'Y1_TRAILS_COND2',\n",
    "       'Y1_TRAILS_COND3', 'CW_RES', 'TR_RES', 'Y1_TAP_SD_TOT_CLOCK']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_all = train_data[['DX', 'DXSUB']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Must drop subjects where ALL data is missing, due to matrix factorixation imputation\n",
    "X_TMCQ_nonull = X_TMCQ.dropna(how='all')\n",
    "X_neuro_nonull = X_neuro.dropna(how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "TMCQ_dx, TMCQ_dxsub = run_classifiers(X_TMCQ_nonull, y_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TMCQ_dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TMCQ_dxsub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "neuro_dx, neuro_dxsub = run_classifiers(X_neuro_nonull, y_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neuro_dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neuro_dxsub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Pipeline for CV "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I just remembered that sklearn.pipeline is a thing.\n",
    "So, I'm going to build that so cross-validation and multiple metrics are easier!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From sklearn:\n",
    "```\n",
    "from sklearn.pipeline import make_pipeline\n",
    "clf = make_pipeline(preprocessing.StandardScaler(), svm.SVC(C=1))\n",
    "cross_val_score(clf, iris.data, iris.target, cv=cv)\n",
    "...                                                 \n",
    "array([ 0.97...,  0.93...,  0.95...])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_validate\n",
    "from fancyimpute import MICE\n",
    "from impute_transform import ImputeTransform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('data/train_data.csv')\n",
    "train_data_small = train_data.sample(n=100)\n",
    "X = train_data_small.drop(columns=['DX','DXSUB'])\n",
    "y = train_data_small['DX'].map({3:1,1:0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf = make_pipeline(ImputeTransform(strategy=MatrixFactorization()), LogisticRegression(random_state=56))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scoring = ['accuracy', 'roc_auc', 'neg_log_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores = cross_validate(clf, X, y, scoring=scoring, cv=2, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Thoughts for the day\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My brain is pretty fried, so I'm gonna call it a night.\n",
    "\n",
    "But here's next steps for tomorrow:\n",
    "- Get this cross_validate function working for log_reg, rf, gb, and xgb\n",
    "- Get this cross_validate function working for DXSUB\n",
    " - cause of the multiclass problem and all that\n",
    "- Explore TMCQ and neuropsych more\n",
    " - The metrics were quite bad on these! And logistic regression actually performed better test-wise than RF and GB!\n",
    "- Discuss next steps with Matt\n",
    " - Clustering ideas\n",
    " - How to approach hyperparam tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clustering Ideas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Subtyping ADHD Using Tempermant Dimensions](https://jamanetwork.com/journals/jamapsychiatry/fullarticle/1885709)\n",
    "\n",
    "The above is a paper written by my boss (Dr. Karalunas) that utilized community detection analysis on the Temperment in Middle Childhood Questionnaire (TMCQ).\n",
    "They had 437 children and used the TMCQ from year 1. \n",
    "They specifically used the [Fast Greedy algorithm](https://arxiv.org/abs/cond-mat/0408187) and found 3 profiles of children, which they labeled as \"mild\", \"surgent\", and \"irritable\".\n",
    "\n",
    "I was thinking of trying to replicate this analysis on the full 901 dataset ([community detection in python](https://yoyoinwanderland.github.io/2017/08/08/Community-Detection-in-Python/)).\n",
    "Then, I was thinking of trying different clustering algorithms to see if the same profiles seem to exist.\n",
    "\n",
    "It'd basically be a study in reproducability.\n",
    "\n",
    "They used physiological and MRI data to externally validate these profiles, which I don't really have. But I might be able to glean something interesting from the neuropsych data? Maybe? IDK. Focus on \"are the profiles there\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Pipeline Continuing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to test the following models:\n",
    "- Logistic Regression\n",
    "- Random Forest\n",
    "- Gradient Boosting\n",
    "- XGBoost\n",
    "\n",
    "With the following metrics:\n",
    "- ROC AUC\n",
    "- Accuracy\n",
    "- Log Loss\n",
    "\n",
    "On the following data:\n",
    "- DX\n",
    "- DXSUB\n",
    "- Neuropsych\n",
    "- TMCQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import make_scorer, accuracy_score, log_loss\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_validate\n",
    "from impute_transform import ImputeTransform\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the models for real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('data/train_data.csv')\n",
    "X = train_data.drop(columns=['DX','DXSUB'])\n",
    "y = train_data['DX'].map({3:1,1:0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log_reg_clf = make_pipeline(ImputeTransform(strategy=MatrixFactorization()),\n",
    "                        LogisticRegression(random_state=56))\n",
    "\n",
    "rf_clf = make_pipeline(ImputeTransform(strategy=MatrixFactorization()),\n",
    "                       RandomForestClassifier(n_jobs=-1, random_state=56))\n",
    "\n",
    "gb_clf = make_pipeline(ImputeTransform(strategy=MatrixFactorization()),\n",
    "                       GradientBoostingClassifier(random_state=56))\n",
    "\n",
    "xgb_clf = make_pipeline(ImputeTransform(strategy=MatrixFactorization()),\n",
    "                        XGBClassifier(max_depth=3, learning_rate=0.1,\n",
    "                        random_state=56))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scoring = ['accuracy', 'roc_auc', 'neg_log_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier_list = [log_reg_clf, rf_clf, gb_clf, xgb_clf]\n",
    "classifier_name = ['LogReg', 'RandomForest', 'GradientBoosting', 'XGB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "classifier_metrics = {}\n",
    "for clf, name in zip(classifier_list, classifier_name):\n",
    "    scores = cross_validate(clf, X, y, scoring=scoring, cv=5, return_train_score=False)\n",
    "    classifier_metrics[name] = scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for classifier, dictionary in classifier_metrics.items():\n",
    "    for metric, score in classifier_metrics[classifier].items():\n",
    "        classifier_metrics[classifier][metric] = np.mean(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "name_of_metrics = ['fit_time', 'score_time', 'test_accuracy',\n",
    "                   'test_neg_log_loss', 'test_roc_auc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metrics_df = pd.DataFrame(data=None,\n",
    "                          index=classifier_name,\n",
    "                          columns=name_of_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for clf in classifier_name:\n",
    "    for metric in name_of_metrics:\n",
    "        metrics_df[metric].loc[clf] = classifier_metrics[clf][metric]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# testing on holdout to see if its somewhat similar or\n",
    "# super off like it was for tmcq...\n",
    "holdout_data = pd.read_csv('data/holdout_data.csv')\n",
    "X_test = holdout_data.drop(columns=['DX','DXSUB'])\n",
    "y_test = holdout_data['DX'].map({3:1,1:0})\n",
    "# yep, it worked there..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGB and LogReg have the best AUC scores, and log_loss scores. Even though GB had the highest test accuracy, I think XGB and LogReg are the models to explore."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TMCQ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I also want to run this on Neuropsych and TMCQ data. It seemed like last time, RF and GB overfit - but XGBoost has regularization so this might mediate that problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_TMCQ = train_data[['Y1_P_TMCQ_ACTIVCONT', 'Y1_P_TMCQ_ACTIVITY', 'Y1_P_TMCQ_AFFIL',\n",
    "       'Y1_P_TMCQ_ANGER', 'Y1_P_TMCQ_FEAR', 'Y1_P_TMCQ_HIP',\n",
    "       'Y1_P_TMCQ_IMPULS', 'Y1_P_TMCQ_INHIBIT', 'Y1_P_TMCQ_SAD',\n",
    "       'Y1_P_TMCQ_SHY', 'Y1_P_TMCQ_SOOTHE', 'Y1_P_TMCQ_ASSERT',\n",
    "       'Y1_P_TMCQ_ATTFOCUS', 'Y1_P_TMCQ_LIP', 'Y1_P_TMCQ_PERCEPT',\n",
    "       'Y1_P_TMCQ_DISCOMF', 'Y1_P_TMCQ_OPENNESS', 'Y1_P_TMCQ_SURGENCY',\n",
    "       'Y1_P_TMCQ_EFFCONT', 'Y1_P_TMCQ_NEGAFFECT']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_TMCQ_nonull = X_TMCQ[X_TMCQ.isnull().sum(axis=1) == 0]\n",
    "y_TMCQ_nonull = y[X_TMCQ.isnull().sum(axis=1) == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Don't need imputation for TMCQ because I removed NaNs\n",
    "log_reg_clf = LogisticRegression(random_state=56)\n",
    "\n",
    "rf_clf = RandomForestClassifier(n_jobs=-1, random_state=56)\n",
    "\n",
    "gb_clf = GradientBoostingClassifier(random_state=56)\n",
    "\n",
    "xgb_clf = XGBClassifier(max_depth=3, learning_rate=0.1,\n",
    "                        random_state=56)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier_list = [log_reg_clf, rf_clf, gb_clf, xgb_clf]\n",
    "classifier_name = ['LogReg', 'RandomForest', 'GradientBoosting', 'XGB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "classifier_metrics_TMCQ = {}\n",
    "for clf, name in zip(classifier_list, classifier_name):\n",
    "    scores = cross_validate(clf, X_TMCQ_nonull, y_TMCQ_nonull, scoring=scoring, cv=5, return_train_score=True)\n",
    "    classifier_metrics_TMCQ[name] = scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for classifier, dictionary in classifier_metrics_TMCQ.items():\n",
    "    for metric, score in classifier_metrics_TMCQ[classifier].items():\n",
    "        classifier_metrics_TMCQ[classifier][metric] = np.mean(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "name_of_metrics = ['fit_time', 'score_time', 'test_accuracy',\n",
    "                   'test_neg_log_loss', 'test_roc_auc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metrics_df_TMCQ = pd.DataFrame(data=None,\n",
    "                          index=classifier_name,\n",
    "                          columns=name_of_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for clf in classifier_name:\n",
    "    for metric in name_of_metrics:\n",
    "        metrics_df_TMCQ[metric].loc[clf] = classifier_metrics_TMCQ[clf][metric]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metrics_df_TMCQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# testing on holdout to see if its somewhat similar\n",
    "X_test_TMCQ = holdout_data[['Y1_P_TMCQ_ACTIVCONT', 'Y1_P_TMCQ_ACTIVITY', 'Y1_P_TMCQ_AFFIL',\n",
    "       'Y1_P_TMCQ_ANGER', 'Y1_P_TMCQ_FEAR', 'Y1_P_TMCQ_HIP',\n",
    "       'Y1_P_TMCQ_IMPULS', 'Y1_P_TMCQ_INHIBIT', 'Y1_P_TMCQ_SAD',\n",
    "       'Y1_P_TMCQ_SHY', 'Y1_P_TMCQ_SOOTHE', 'Y1_P_TMCQ_ASSERT',\n",
    "       'Y1_P_TMCQ_ATTFOCUS', 'Y1_P_TMCQ_LIP', 'Y1_P_TMCQ_PERCEPT',\n",
    "       'Y1_P_TMCQ_DISCOMF', 'Y1_P_TMCQ_OPENNESS', 'Y1_P_TMCQ_SURGENCY',\n",
    "       'Y1_P_TMCQ_EFFCONT', 'Y1_P_TMCQ_NEGAFFECT']]\n",
    "y_test_TMCQ = holdout_data['DX'].map({3:1,1:0})\n",
    "\n",
    "X_test_TMCQ_nonull = X_test_TMCQ[X_test_TMCQ.isnull().sum(axis=1) == 0]\n",
    "y_test_TMCQ_nonull = y_test[X_test_TMCQ.isnull().sum(axis=1) == 0]\n",
    "# also get similar results! yay!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Neuropsych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_neuro = train_data[['STOP_SSRTAVE_Y1', 'DPRIME1_Y1', 'DPRIME2_Y1', 'SSBK_NUMCOMPLETE_Y1',\n",
    "       'SSFD_NUMCOMPLETE_Y1', 'V_Y1', 'Y1_CLWRD_COND1', 'Y1_CLWRD_COND2',\n",
    "       'Y1_DIGITS_BKWD_RS', 'Y1_DIGITS_FRWD_RS', 'Y1_TRAILS_COND2',\n",
    "       'Y1_TRAILS_COND3', 'CW_RES', 'TR_RES', 'Y1_TAP_SD_TOT_CLOCK']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_neuro_nonull = X_neuro[X_neuro.isnull().sum(axis=1) != X_neuro.shape[1]]\n",
    "y_neuro_nonull = y[X_neuro.isnull().sum(axis=1) != X_neuro.shape[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log_reg_clf = make_pipeline(ImputeTransform(strategy=MatrixFactorization()),\n",
    "                        LogisticRegression(random_state=56))\n",
    "\n",
    "rf_clf = make_pipeline(ImputeTransform(strategy=MatrixFactorization()),\n",
    "                       RandomForestClassifier(n_jobs=-1, random_state=56))\n",
    "\n",
    "gb_clf = make_pipeline(ImputeTransform(strategy=MatrixFactorization()),\n",
    "                       GradientBoostingClassifier(random_state=56))\n",
    "\n",
    "xgb_clf = make_pipeline(ImputeTransform(strategy=MatrixFactorization()),\n",
    "                        XGBClassifier(max_depth=3, learning_rate=0.1,\n",
    "                        random_state=56))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier_list = [log_reg_clf, rf_clf, gb_clf, xgb_clf]\n",
    "classifier_name = ['LogReg', 'RandomForest', 'GradientBoosting', 'XGB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "classifier_metrics_neuro = {}\n",
    "for clf, name in zip(classifier_list, classifier_name):\n",
    "    scores = cross_validate(clf,\n",
    "                            X_neuro_nonull, y_neuro_nonull,\n",
    "                            scoring=scoring, cv=5,\n",
    "                            return_train_score=True)\n",
    "    classifier_metrics_neuro[name] = scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for classifier, dictionary in classifier_metrics_neuro.items():\n",
    "    for metric, score in classifier_metrics_neuro[classifier].items():\n",
    "        classifier_metrics_neuro[classifier][metric] = np.mean(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "name_of_metrics = ['fit_time', 'score_time', 'test_accuracy',\n",
    "                   'test_neg_log_loss', 'test_roc_auc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metrics_df_neuro = pd.DataFrame(data=None,\n",
    "                          index=classifier_name,\n",
    "                          columns=name_of_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for clf in classifier_name:\n",
    "    for metric in name_of_metrics:\n",
    "        metrics_df_neuro[metric].loc[clf] = classifier_metrics_neuro[clf][metric]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "metrics_df_neuro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# testing on holdout to see if its somewhat similar\n",
    "X_test_neuro = holdout_data[['STOP_SSRTAVE_Y1', 'DPRIME1_Y1', 'DPRIME2_Y1', 'SSBK_NUMCOMPLETE_Y1',\n",
    "       'SSFD_NUMCOMPLETE_Y1', 'V_Y1', 'Y1_CLWRD_COND1', 'Y1_CLWRD_COND2',\n",
    "       'Y1_DIGITS_BKWD_RS', 'Y1_DIGITS_FRWD_RS', 'Y1_TRAILS_COND2',\n",
    "       'Y1_TRAILS_COND3', 'CW_RES', 'TR_RES', 'Y1_TAP_SD_TOT_CLOCK']]\n",
    "y_test_neuro = holdout_data['DX'].map({3:1,1:0})\n",
    "\n",
    "X_test_neuro_nonull = X_test_neuro[X_test_neuro.isnull().sum(axis=1) != X_test_neuro.shape[1]]\n",
    "y_test_neuro_nonull = y_test_neuro[X_test_neuro.isnull().sum(axis=1) != X_test_neuro.shape[1]]\n",
    "# yep, looks good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Log Reg and XGB are the most robust and accurate models. RF and GB can be prone to overfitting, but XGB fixes this problem with regularization.\n",
    "\n",
    "So, I will focus on parameter optimization of LogisticRegression and XGB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Tuning for XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the guidelines set out here: [Complete Guide to Parameter Tuning in XGBoost](https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "from model_metrics import *\n",
    "from fancyimpute import *\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from impute_transform import ImputeTransform\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('data/train_data.csv')\n",
    "train_data_small = train_data.sample(n=400)\n",
    "X = train_data_small.drop(columns=['DX','DXSUB'])\n",
    "y = train_data_small['DX'].map({3:1,1:0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impute = ImputeTransform(strategy=MICE())\n",
    "clf = XGBClassifier(\n",
    "                  learning_rate = 0.1,\n",
    "                  n_estimators = 1000,\n",
    "                  max_depth = 5,\n",
    "                  min_child_weight = 1,\n",
    "                  gamma = 0,\n",
    "                  subsample = 0.8,\n",
    "                  colsample_bytree = 0.8,\n",
    "                  scale_pos_weight=1,\n",
    "                  objective = 'binary:logistic',\n",
    "                  n_jobs = -1,\n",
    "                  random_state=56)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "steps = [('impute_transform', impute),\n",
    "         ('xgboost', clf)]\n",
    "\n",
    "pipeline = Pipeline(steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Fix learning rate and number of estimators for tuning tree-based parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_test1 = {'xgboost__n_estimators': range(20,101,10)}\n",
    "\n",
    "gsearch1 = GridSearchCV(pipeline,\n",
    "                        param_grid=param_test1,\n",
    "                        scoring='roc_auc',\n",
    "                        iid=False, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "gsearch1.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gsearch1.best_params_, gsearch1.best_score_)\n",
    "best_n_estimators = gsearch1.best_params_['xgboost__n_estimators']\n",
    "_ = pipeline.set_params(xgboost__n_estimators=best_n_estimators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Tune max_depth and min_child_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_test2 = {'xgboost__max_depth': range(3,10,2),\n",
    "               'xgboost__min_child_weight': range(1,6,2)}\n",
    "\n",
    "gsearch2 = GridSearchCV(pipeline,\n",
    "                        param_grid=param_test2,\n",
    "                        scoring='roc_auc',\n",
    "                        iid=False, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "gsearch2.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gsearch2.best_params_, gsearch2.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2b: Find optimum values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_test2a = {'xgboost__max_depth': [1,2,3,4],\n",
    "                'xgboost__min_child_weight': [1,2,3]}\n",
    "gsearch2a = GridSearchCV(pipeline,\n",
    "                         param_grid=param_test2a,\n",
    "                         scoring='roc_auc',\n",
    "                         iid=False, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "gsearch2a.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(gsearch2a.best_params_, gsearch2a.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set the new parameters\n",
    "best_max_depth = gsearch2a.best_params_['xgboost__max_depth']\n",
    "best_child_weight = gsearch2a.best_params_['xgboost__min_child_weight']\n",
    "_ = pipeline.set_params(xgboost__max_depth=best_max_depth,\n",
    "                        xgboost__min_child_weight=best_child_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Tune gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_test3 = {'xgboost__gamma': [i/10.0 for i in range(0,5)]}\n",
    "gsearch3 = GridSearchCV(pipeline,\n",
    "                        param_grid=param_test3,\n",
    "                        scoring='roc_auc',\n",
    "                        iid=False, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "gsearch3.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gsearch3.best_params_, gsearch3.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set the new parameters\n",
    "best_gamma = gsearch3.best_params_['xgboost__gamma']\n",
    "_ = pipeline.set_params(xgboost__gamma=best_max_depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3b: Re-calibrate n_estimators for updated parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_test3b = {'xgboost__n_estimators': range(20,101,10)}\n",
    "\n",
    "gsearch3b = GridSearchCV(pipeline,\n",
    "                         param_grid=param_test3b,\n",
    "                         scoring='roc_auc',\n",
    "                         iid=False, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "gsearch3b.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gsearch3b.best_params_, gsearch3b.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_n_estimators = gsearch3b.best_params_['xgboost__n_estimators']\n",
    "_ = pipeline.set_params(xgboost__n_estimators=best_n_estimators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Tune subsample and colsample_bytree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# probably skippable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Tuning Regularization Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# probably skippable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Reducing Learning Rate, Add Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_ = pipeline.set_params(xgboost__learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_test6 = {'xgboost__n_estimators': range(60,200,10)}\n",
    "\n",
    "gsearch6 = GridSearchCV(pipeline,\n",
    "                        param_grid=param_test6,\n",
    "                        scoring='roc_auc',\n",
    "                        iid=False, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "gsearch6.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gsearch6.best_params_, gsearch6.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_n_estimators = gsearch6.best_params_['xgboost__n_estimators']\n",
    "_ = pipeline.set_params(xgboost__n_estimators=best_n_estimators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Fit full model, examine feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp = pd.Series(pipeline.steps[1][1].feature_importances_,index=X.columns).sort_values(ascending=False)\n",
    "feat_imp.plot(kind='bar', title='Feature Importances')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
