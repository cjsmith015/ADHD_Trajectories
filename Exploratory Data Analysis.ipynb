{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "from model_metrics import *\n",
    "from fancyimpute import *\n",
    "import pickle\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_data = pd.read_csv('data/Christie_diagnosis_20180118.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Imputation Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For information on algorithms, see [fancyimpute](https://pypi.python.org/pypi/fancyimpute)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make all the solver objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "KNN_solver = KNN(k=5)\n",
    "softimpute_solver = SoftImpute()\n",
    "MICE_solver = MICE()\n",
    "simple_solver = SimpleFill()\n",
    "iterativeSVD_solver = IterativeSVD()\n",
    "matrixfactorization_solver = MatrixFactorization()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dataframe from the complete data in `train_data`. Then, randomly insert some NaNs for MSE testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop NaNs\n",
    "complete_data = train_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop DX and DXSUB\n",
    "complete_data.drop(columns=['DX', 'DXSUB'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Randomly insert NaNs\n",
    "nan_inserted_data = complete_data.copy()\n",
    "import random\n",
    "ix = [(row, col) for row in range(complete_data.shape[0]) for col in range(complete_data.shape[1])]\n",
    "for row, col in random.sample(ix, int(round(.1*len(ix)))):\n",
    "    nan_inserted_data.iat[row, col] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "missing_mask = nan_inserted_data.isna().any(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete those missing dataframes with the various solvers!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_imputation(solver, df):\n",
    "    \"\"\"Impute the data using imputation methods\"\"\"\n",
    "    impute_data = df.values\n",
    "    data_index = df.index\n",
    "    data_cols = df.columns\n",
    "\n",
    "    impute_data_filled = solver.complete(impute_data)\n",
    "    impute_df = pd.DataFrame(impute_data_filled, index=data_index, columns=data_cols)\n",
    "    return impute_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "KNN_df = test_imputation(KNN_solver, nan_inserted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "softimpute_df = test_imputation(softimpute_solver, nan_inserted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MICE_df = test_imputation(MICE_solver, nan_inserted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "simple_df = test_imputation(simple_solver, nan_inserted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iterative_df = test_imputation(iterativeSVD_solver, nan_inserted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "matrixfact_df = test_imputation(matrixfactorization_solver, nan_inserted_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now cast as ints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "solver_list = [KNN_df, softimpute_df, MICE_df,\n",
    "               simple_df, iterative_df, matrixfact_df]\n",
    "solver_names = ['KNN', 'SoftImpute', 'MICE', 'SimpleFill',\n",
    "                   'IterativeSVD', 'MatrixFactorization']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "KNN_df_round = KNN_df.copy()\n",
    "softimpute_df_round = softimpute_df.copy()\n",
    "MICE_df_round = MICE_df.copy()\n",
    "simple_df_round = simple_df.copy()\n",
    "iterative_df_round = iterative_df.copy()\n",
    "matrixfact_df_round = matrixfact_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "round_list = [KNN_df_round, softimpute_df_round, MICE_df_round,\n",
    "              simple_df_round, iterative_df_round, matrixfact_df_round]\n",
    "round_names = ['KNN_round', 'SoftImpute_round', 'MICE_round',\n",
    "            'SimpleFill_round', 'IterativeSVD_round', 'MatrixFact_round']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "int_cols = ['SSBK_NUMCOMPLETE_Y1', 'SSFD_NUMCOMPLETE_Y1',\n",
    "            'Y1_CLWRD_COND1', 'Y1_CLWRD_COND2', 'Y1_DIGITS_BKWD_RS',\n",
    "            'Y1_DIGITS_FRWD_RS', 'Y1_TRAILS_COND2', 'Y1_TRAILS_COND3']\n",
    "for df in round_list:\n",
    "    for col in int_cols:\n",
    "        df[col] = df[col].astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create MSEs for each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_df_list = solver_list + round_list\n",
    "total_df_names = solver_names + round_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mse_df = pd.DataFrame(index=total_df_names, columns=complete_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "for df, name in zip(total_df_list, total_df_names):\n",
    "    mse = ((df[missing_mask] - complete_data[missing_mask]) ** 2).mean()\n",
    "    mse_df.loc[name] = mse\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which method has the lowest MSEs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write `true` for minimums in each col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mse_df_bool = mse_df.copy()\n",
    "for col in mse_df.columns:\n",
    "    mse_df_bool[col] = (mse_df_bool[col] == np.min(mse_df_bool[col]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mse_df_bool.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "int_cols_nodx = ['SSBK_NUMCOMPLETE_Y1',\n",
    " 'SSFD_NUMCOMPLETE_Y1',\n",
    " 'Y1_CLWRD_COND1',\n",
    " 'Y1_CLWRD_COND2',\n",
    " 'Y1_DIGITS_BKWD_RS',\n",
    " 'Y1_DIGITS_FRWD_RS',\n",
    " 'Y1_TRAILS_COND2',\n",
    " 'Y1_TRAILS_COND3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_df_bool[int_cols_nodx].sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, MICE seems to do the best for columns that are technically integers (3 out of 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like MatrixFactorization is the best option. (out of 38 cols, 24 went to MatrixFactorization for the lowest MSE)\n",
    "\n",
    "Rounding does not improve the MSE. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing for leaky data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I had really high accuracy on my first logistic regression model (91% test accuracy on smaller train/test split, and 92% accuracy on cross-validated log models).\n",
    "\n",
    "So, I want to investigate if I have any leaky data columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = train_data.drop(columns=['DX','DXSUB'])\n",
    "y_train = train_data['DX']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_small, X_test_small, y_train_small, y_test_small = train_test_split(\n",
    "                    X_train, y_train, test_size=0.2, random_state=56)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy_list = []\n",
    "for col in X_train_small.columns:\n",
    "    # Drop the column\n",
    "    X_train_dataset = X_train_small.drop(columns=col).values\n",
    "    X_test_dataset = X_test_small.drop(columns=col).values\n",
    "    \n",
    "    # Impute the data if missing numbers\n",
    "    if np.sum(np.isnan(X_train_dataset)) > 0:\n",
    "        X_train_final = impute_data(X_train_dataset)\n",
    "    else:\n",
    "        X_train_final = X_train_dataset.copy()\n",
    "\n",
    "    if np.sum(np.isnan(X_test_dataset)) > 0:\n",
    "        X_test_final = impute_data(X_test_dataset)\n",
    "    else:\n",
    "        X_test_final = X_test_dataset.copy()\n",
    "        \n",
    "    # Fit model\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train_final, y_train_small)\n",
    "    \n",
    "    # Score model\n",
    "    accuracy = model.score(y_test_final, y_test_small)\n",
    "    accuracy_list.append((col, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_list\n",
    "for col, acc in accuracy_list:\n",
    "    print(\"Accuracy removing {}: \\t \\t {:2.2f}\".format(col, acc).expandtabs(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_small_impute = impute_data(X_train_small.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logreg.fit(X_train_small_impute, y_train_small.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg.score(impute_data(X_test_small.values), y_test_small.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like there aren't any leaky variables. I just have high accuracy.\n",
    "\n",
    "This makes sense - the lab wouldn't administer tests or behavioral questionnaires that don't have something to do with ADHD. So a straight logistical model is pretty accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going forward, I want to do a few things:\n",
    "\n",
    "- How high can I get the accuracy? Test out a few different models (RF, Gradient Boosting)\n",
    "- What's the spread of the predicted probas like?\n",
    "- Test out on DXSUB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Model Metrics Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_DX = train_data.drop(columns=['DX','DXSUB'])\n",
    "y_train_DX = train_data['DX']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_small, X_test_small, y_train_small, y_test_small = train_test_split(\n",
    "                    X_train_DX, y_train_DX, test_size=0.2, random_state=56)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logmod = LogisticRegression()\n",
    "logmod.fit(impute_data(X_train_small.values), y_train_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_prob_dx = logmod.predict_proba(impute_data(X_test_small.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prob_dx = logmod.predict(impute_data(X_test_small.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(pred_prob_dx[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_jitter(data, jitter=0.1):\n",
    "    return np.random.uniform(-jitter, jitter, size=data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,2))\n",
    "\n",
    "_ = ax.scatter(pred_prob_dx[:,0], make_jitter(pred_prob_dx[:,0]), c=np.vectorize(dx_dict.get)(y_test_small),\n",
    "           s=40, alpha=0.5)\n",
    "_ = ax.set_xlim(0,1)\n",
    "_ = ax.set_title('Predicted Probability of Positive vs Negative Classes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test_small, prob_dx, pos_label=3, drop_intermediate=False)\n",
    "roc_auc = auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(fpr, tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I created logistic regression, random forest, and gradient boosting models. I want to see the MSE and accuracy on train/test, cross-validated (k-fold=10), when predicting DX, and when predicting DXSUB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train_data = pd.read_csv('data/train_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%%capture\n",
    "#classifier_metrics = run_classifiers(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#with open('classifier_metrics.pkl', 'wb') as f:\n",
    "    #pickle.dump(classifier_metrics, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classification_metrics = pickle.load(open(\"classifier_metrics.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[clf][pred][metric][train/test]\n",
    "# Logistic Regression\n",
    "lr_dx_mse_train = np.mean(classification_metrics[0][0][0][0])\n",
    "lr_dx_mse_test = np.mean(classification_metrics[0][0][0][1])\n",
    "lr_dx_acc_train = np.mean(classification_metrics[0][0][1][0])\n",
    "lr_dx_acc_test = np.mean(classification_metrics[0][0][1][1])\n",
    "\n",
    "lr_dxsub_mse_train = np.mean(classification_metrics[0][1][0][0])\n",
    "lr_dxsub_mse_test = np.mean(classification_metrics[0][1][0][1])\n",
    "lr_dxsub_acc_train = np.mean(classification_metrics[0][1][1][0])\n",
    "lr_dxsub_acc_test = np.mean(classification_metrics[0][1][1][1])\n",
    "\n",
    "# Random Forest\n",
    "rf_dx_mse_train = np.mean(classification_metrics[1][0][0][0])\n",
    "rf_dx_mse_test = np.mean(classification_metrics[1][0][0][1])\n",
    "rf_dx_acc_train = np.mean(classification_metrics[1][0][1][0])\n",
    "rf_dx_acc_test = np.mean(classification_metrics[1][0][1][1])\n",
    "\n",
    "rf_dxsub_mse_train = np.mean(classification_metrics[1][1][0][0])\n",
    "rf_dxsub_mse_test = np.mean(classification_metrics[1][1][0][1])\n",
    "rf_dxsub_acc_train = np.mean(classification_metrics[1][1][1][0])\n",
    "rf_dxsub_acc_test = np.mean(classification_metrics[1][1][1][1])\n",
    "\n",
    "# Gradient Boosting\n",
    "gb_dx_mse_train = np.mean(classification_metrics[2][0][0][0])\n",
    "gb_dx_mse_test = np.mean(classification_metrics[2][0][0][1])\n",
    "gb_dx_acc_train = np.mean(classification_metrics[2][0][1][0])\n",
    "gb_dx_acc_test = np.mean(classification_metrics[2][0][1][1])\n",
    "\n",
    "gb_dxsub_mse_train = np.mean(classification_metrics[2][1][0][0])\n",
    "gb_dxsub_mse_test = np.mean(classification_metrics[2][1][0][1])\n",
    "gb_dxsub_acc_train = np.mean(classification_metrics[2][1][1][0])\n",
    "gb_dxsub_acc_test = np.mean(classification_metrics[2][1][1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make dataframes\n",
    "metrics_dx_dict = {'DX_acc_train': [lr_dx_acc_train, rf_dx_acc_train, gb_dx_acc_train],\n",
    "                   'DX_acc_test': [lr_dx_acc_test, rf_dx_acc_test, gb_dx_acc_test],\n",
    "                   'DX_mse_train': [lr_dx_mse_train, rf_dx_mse_train, gb_dx_mse_train],\n",
    "                   'DX_mse_test': [lr_dx_mse_test, rf_dx_mse_test, gb_dx_mse_test]}\n",
    "\n",
    "metrics_DX = pd.DataFrame(data=metrics_dx_dict,\n",
    "                          columns=['DX_acc_train', 'DX_acc_test', 'DX_mse_train', 'DX_mse_test'],\n",
    "                          index=['LogReg', 'RandomForest', 'GradBoost'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metrics_dxsub_dict = {'DXSUB_acc_train': [lr_dxsub_acc_train, rf_dxsub_acc_train, gb_dxsub_acc_train],\n",
    "                   'DXSUB_acc_test': [lr_dxsub_acc_test, rf_dxsub_acc_test, gb_dxsub_acc_test],\n",
    "                   'DXSUB_mse_train': [lr_dxsub_mse_train, rf_dxsub_mse_train, gb_dxsub_mse_train],\n",
    "                   'DXSUB_mse_test': [lr_dxsub_mse_test, rf_dxsub_mse_test, gb_dxsub_mse_test]}\n",
    "\n",
    "metrics_DXSUB = pd.DataFrame(data=metrics_dxsub_dict,\n",
    "                             columns=['DXSUB_acc_train', 'DXSUB_acc_test', 'DXSUB_mse_train', 'DXSUB_mse_test'],\n",
    "                             index=['LogReg', 'RandomForest', 'GradBoost'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_DX.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_DXSUB.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neuropsych vs TMCQ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I've evaluated models on all the data, I want to check out what accuracy and mse looks like for models run JUST on neuropsych, and JUST on TMCQ.\n",
    "\n",
    "I'll use the same exact procedure as above, just with different X matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('data/train_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_TMCQ = train_data[['Y1_P_TMCQ_ACTIVCONT', 'Y1_P_TMCQ_ACTIVITY', 'Y1_P_TMCQ_AFFIL',\n",
    "       'Y1_P_TMCQ_ANGER', 'Y1_P_TMCQ_FEAR', 'Y1_P_TMCQ_HIP',\n",
    "       'Y1_P_TMCQ_IMPULS', 'Y1_P_TMCQ_INHIBIT', 'Y1_P_TMCQ_SAD',\n",
    "       'Y1_P_TMCQ_SHY', 'Y1_P_TMCQ_SOOTHE', 'Y1_P_TMCQ_ASSERT',\n",
    "       'Y1_P_TMCQ_ATTFOCUS', 'Y1_P_TMCQ_LIP', 'Y1_P_TMCQ_PERCEPT',\n",
    "       'Y1_P_TMCQ_DISCOMF', 'Y1_P_TMCQ_OPENNESS', 'Y1_P_TMCQ_SURGENCY',\n",
    "       'Y1_P_TMCQ_EFFCONT', 'Y1_P_TMCQ_NEGAFFECT']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_TMCQ.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_neuro = train_data[['STOP_SSRTAVE_Y1', 'DPRIME1_Y1', 'DPRIME2_Y1', 'SSBK_NUMCOMPLETE_Y1',\n",
    "       'SSFD_NUMCOMPLETE_Y1', 'V_Y1', 'Y1_CLWRD_COND1', 'Y1_CLWRD_COND2',\n",
    "       'Y1_DIGITS_BKWD_RS', 'Y1_DIGITS_FRWD_RS', 'Y1_TRAILS_COND2',\n",
    "       'Y1_TRAILS_COND3', 'CW_RES', 'TR_RES', 'Y1_TAP_SD_TOT_CLOCK']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_all = train_data[['DX', 'DXSUB']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Must drop subjects where ALL data is missing, due to matrix factorixation imputation\n",
    "X_TMCQ_nonull = X_TMCQ.dropna(how='all')\n",
    "X_neuro_nonull = X_neuro.dropna(how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "TMCQ_dx, TMCQ_dxsub = run_classifiers(X_TMCQ_nonull, y_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TMCQ_dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TMCQ_dxsub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "neuro_dx, neuro_dxsub = run_classifiers(X_neuro_nonull, y_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuro_dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuro_dxsub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploring more \"modern\" boosting techniques, starting with XGBoost. If it looks promising, I'll work on hyperparam tuning on this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param = {'max_depth':2, 'eta':0.1, 'objective':'binary:logistic'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(max_depth=3, learning_rate=0.1, n_estimators=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Pipeline for CV "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I just remembered that sklearn.pipeline is a thing.\n",
    "So, I'm going to build that so cross-validation and multiple metrics are easier!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From sklearn:\n",
    "```\n",
    "from sklearn.pipeline import make_pipeline\n",
    "clf = make_pipeline(preprocessing.StandardScaler(), svm.SVC(C=1))\n",
    "cross_val_score(clf, iris.data, iris.target, cv=cv)\n",
    "...                                                 \n",
    "array([ 0.97...,  0.93...,  0.95...])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from fancyimpute import MICE\n",
    "from impute_transform import ImputeTransform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('data/train_data.csv')\n",
    "train_data_small = train_data.sample(n=100)\n",
    "X = train_data_small.drop(columns=['DX','DXSUB'])\n",
    "y = train_data_small['DX']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "solver = MICE()\n",
    "X_filled = solver.complete(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression().fit(X_filled, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impute = ImputeTransform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<impute_transform.ImputeTransform at 0x7fdddfaa3a58>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "impute.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf = make_pipeline(ImputeTransform(), LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     STOP_SSRTAVE_Y1  DPRIME1_Y1  DPRIME2_Y1  SSBK_NUMCOMPLETE_Y1  \\\n",
      "376       221.590000    1.504850    3.672012                  7.0   \n",
      "516       310.903333    2.191326    3.496619                  3.0   \n",
      "270       281.981667    1.155605    2.052807                  7.0   \n",
      "219       164.895000    0.570501    2.077934                  3.0   \n",
      "371       159.714286    1.239333    3.053595                  9.0   \n",
      "280       235.775714    2.106385    3.449213                 11.0   \n",
      "144       263.381429    1.541763    3.496619                  5.0   \n",
      "463       243.821429    0.791300    2.540476                  9.0   \n",
      "418       665.810000   -0.168794    0.183467                  3.0   \n",
      "510              NaN         NaN         NaN                  NaN   \n",
      "526       134.058571    0.535341    1.873098                 11.0   \n",
      "79        326.876000    0.220475    1.229513                 11.0   \n",
      "572       354.424000    1.980419    4.078810                  7.0   \n",
      "113       189.041429    0.936479    2.461945                 13.0   \n",
      "479       398.258333    0.328547    1.603685                  5.0   \n",
      "558       173.178571    0.389197    1.983159                  7.0   \n",
      "429              NaN    0.219142    2.699514                  7.0   \n",
      "386              NaN         NaN         NaN                  NaN   \n",
      "391       410.424286    2.329183    3.247068                  9.0   \n",
      "257       231.126000    3.447849    4.378807                  9.0   \n",
      "319       290.252000    0.220475    1.670777                  3.0   \n",
      "111       416.795000         NaN         NaN                  9.0   \n",
      "414       121.284000    1.217741    2.687111                 11.0   \n",
      "596       170.712500    0.338955    0.999484                  7.0   \n",
      "6                NaN    0.570501    2.451543                  5.0   \n",
      "577       251.210000    0.116445    0.882328                  9.0   \n",
      "467       146.860000    1.150813    2.466870                  7.0   \n",
      "241       259.688333    1.685913    2.284410                  7.0   \n",
      "222       219.692000    1.419076    2.877071                 11.0   \n",
      "501              NaN         NaN         NaN                  NaN   \n",
      "..               ...         ...         ...                  ...   \n",
      "402       209.025000         NaN         NaN                  7.0   \n",
      "274       337.870000    0.992648    2.716659                  7.0   \n",
      "250       208.085000    1.286365    2.741759                  9.0   \n",
      "63        462.710000    0.577679    1.133654                  7.0   \n",
      "512              NaN         NaN         NaN                  NaN   \n",
      "356       182.024286    1.819064    3.519310                  7.0   \n",
      "455       515.860000   -0.058836    0.800181                  9.0   \n",
      "532       196.390000    0.717337    2.861654                 11.0   \n",
      "86        253.780000    0.826416    2.149468                  3.0   \n",
      "96        258.824286    0.496862    2.259897                  5.0   \n",
      "8         251.401429    1.095273    2.676312                  7.0   \n",
      "210              NaN         NaN         NaN                  NaN   \n",
      "173       170.666667    0.557438    1.840120                  7.0   \n",
      "118       420.050000    1.369056    1.964806                  9.0   \n",
      "11               NaN         NaN         NaN                  NaN   \n",
      "462       176.298000         NaN         NaN                  7.0   \n",
      "385       277.025714    1.968528    3.182111                  NaN   \n",
      "269       343.276667    0.969509    2.451491                  5.0   \n",
      "176              NaN         NaN         NaN                  5.0   \n",
      "206              NaN    0.657484    1.432853                  5.0   \n",
      "408              NaN         NaN         NaN                  NaN   \n",
      "193       288.834000    0.176776    0.600132                  3.0   \n",
      "573              NaN         NaN         NaN                  NaN   \n",
      "46        204.394000    1.901600    3.437897                 11.0   \n",
      "211       246.235000    0.553840    1.531977                  3.0   \n",
      "600       285.440000    0.219561    1.275302                  3.0   \n",
      "409              NaN         NaN         NaN                  NaN   \n",
      "580       520.716667    0.116445    1.487305                  7.0   \n",
      "513       475.075000    1.204412    2.484318                  9.0   \n",
      "128              NaN    1.156307    2.982769                  7.0   \n",
      "\n",
      "     SSFD_NUMCOMPLETE_Y1    V_Y1  Y1_CLWRD_COND1  Y1_CLWRD_COND2  \\\n",
      "376                  9.0  3.7920            35.0            24.0   \n",
      "516                 13.0  2.8193            29.0            22.0   \n",
      "270                  7.0  2.6207            50.0            31.0   \n",
      "219                 11.0  3.0104            64.0            36.0   \n",
      "371                  7.0  3.3263            27.0            21.0   \n",
      "280                 13.0  2.7706            36.0            25.0   \n",
      "144                 11.0  4.2439            44.0            25.0   \n",
      "463                 11.0  2.5280            60.0            42.0   \n",
      "418                  7.0  1.7976            96.0            44.0   \n",
      "510                  NaN     NaN             NaN             NaN   \n",
      "526                  5.0  1.9671            42.0            25.0   \n",
      "79                   9.0  1.4740            70.0            47.0   \n",
      "572                  7.0  3.3467            40.0            31.0   \n",
      "113                  9.0  3.0342            42.0            31.0   \n",
      "479                  5.0  2.4621            51.0            30.0   \n",
      "558                 11.0  4.0693            48.0            33.0   \n",
      "429                  9.0  4.2359            43.0            31.0   \n",
      "386                  NaN     NaN             NaN             NaN   \n",
      "391                  9.0  3.7350            37.0            19.0   \n",
      "257                  9.0  4.2382            30.0            19.0   \n",
      "319                  9.0  2.3454            44.0            36.0   \n",
      "111                  5.0  1.8469            50.0            31.0   \n",
      "414                 11.0  3.2507            52.0            44.0   \n",
      "596                  7.0  2.2562            71.0            29.0   \n",
      "6                    7.0     NaN            55.0            32.0   \n",
      "577                  3.0  3.1694            58.0            36.0   \n",
      "467                 11.0  3.1720            52.0            41.0   \n",
      "241                  3.0  4.1131            38.0            27.0   \n",
      "222                 11.0  3.6590            27.0            20.0   \n",
      "501                  NaN     NaN             NaN             NaN   \n",
      "..                   ...     ...             ...             ...   \n",
      "402                  5.0  2.7505            39.0            25.0   \n",
      "274                  7.0  2.7517            26.0            24.0   \n",
      "250                  7.0  3.2695            47.0            50.0   \n",
      "63                   7.0  0.9545            78.0            42.0   \n",
      "512                  NaN     NaN             NaN             NaN   \n",
      "356                  9.0  3.9264            32.0            27.0   \n",
      "455                  7.0  2.8099            64.0            33.0   \n",
      "532                 13.0  3.7357            43.0            33.0   \n",
      "86                   5.0  3.0551            50.0            26.0   \n",
      "96                   7.0  4.5226            61.0            34.0   \n",
      "8                    7.0  4.0320            38.0            31.0   \n",
      "210                  NaN     NaN             NaN             NaN   \n",
      "173                  9.0  3.7080            48.0            34.0   \n",
      "118                  7.0  2.7154            39.0            30.0   \n",
      "11                   7.0     NaN            53.0            45.0   \n",
      "462                  9.0  2.9822            34.0            28.0   \n",
      "385                  NaN  4.0287            34.0            28.0   \n",
      "269                 11.0  2.7034            31.0            25.0   \n",
      "176                  3.0     NaN            51.0            34.0   \n",
      "206                  7.0  1.6069            40.0            27.0   \n",
      "408                  NaN     NaN             NaN             NaN   \n",
      "193                  3.0  2.7591            48.0            26.0   \n",
      "573                  NaN     NaN             NaN             NaN   \n",
      "46                   9.0  4.1874            29.0            20.0   \n",
      "211                  5.0  2.5036            48.0            33.0   \n",
      "600                  7.0  2.0817            60.0            32.0   \n",
      "409                  NaN     NaN             NaN             NaN   \n",
      "580                  9.0  2.4632            47.0            32.0   \n",
      "513                  9.0  2.1160            60.0            41.0   \n",
      "128                  9.0     NaN            57.0            44.0   \n",
      "\n",
      "     Y1_DIGITS_BKWD_RS  Y1_DIGITS_FRWD_RS         ...           \\\n",
      "376                9.0               12.0         ...            \n",
      "516               13.0               12.0         ...            \n",
      "270                6.0                8.0         ...            \n",
      "219                4.0                8.0         ...            \n",
      "371                7.0               10.0         ...            \n",
      "280                9.0                9.0         ...            \n",
      "144                6.0                7.0         ...            \n",
      "463                5.0               10.0         ...            \n",
      "418                6.0                8.0         ...            \n",
      "510                NaN                NaN         ...            \n",
      "526                7.0                7.0         ...            \n",
      "79                 7.0                8.0         ...            \n",
      "572                0.0                7.0         ...            \n",
      "113                8.0                8.0         ...            \n",
      "479                6.0                9.0         ...            \n",
      "558                5.0                9.0         ...            \n",
      "429                6.0               10.0         ...            \n",
      "386                NaN                NaN         ...            \n",
      "391                8.0                8.0         ...            \n",
      "257                8.0               14.0         ...            \n",
      "319                8.0                4.0         ...            \n",
      "111                7.0                7.0         ...            \n",
      "414                8.0               11.0         ...            \n",
      "596                6.0               10.0         ...            \n",
      "6                  7.0               10.0         ...            \n",
      "577                6.0                6.0         ...            \n",
      "467                5.0                8.0         ...            \n",
      "241                6.0                9.0         ...            \n",
      "222                7.0                7.0         ...            \n",
      "501                NaN                NaN         ...            \n",
      "..                 ...                ...         ...            \n",
      "402                4.0                9.0         ...            \n",
      "274                8.0               11.0         ...            \n",
      "250                6.0                8.0         ...            \n",
      "63                 4.0                5.0         ...            \n",
      "512                NaN                NaN         ...            \n",
      "356                9.0               11.0         ...            \n",
      "455                6.0                8.0         ...            \n",
      "532               12.0               12.0         ...            \n",
      "86                 7.0               10.0         ...            \n",
      "96                 6.0                7.0         ...            \n",
      "8                  6.0               10.0         ...            \n",
      "210                NaN                NaN         ...            \n",
      "173                7.0               10.0         ...            \n",
      "118                9.0                6.0         ...            \n",
      "11                 6.0                8.0         ...            \n",
      "462                5.0                6.0         ...            \n",
      "385               12.0               15.0         ...            \n",
      "269                7.0               10.0         ...            \n",
      "176                4.0                7.0         ...            \n",
      "206                4.0                5.0         ...            \n",
      "408                NaN                NaN         ...            \n",
      "193                6.0               10.0         ...            \n",
      "573                NaN                NaN         ...            \n",
      "46                13.0               15.0         ...            \n",
      "211                6.0                6.0         ...            \n",
      "600                6.0                9.0         ...            \n",
      "409                NaN                NaN         ...            \n",
      "580                9.0                6.0         ...            \n",
      "513                6.0                6.0         ...            \n",
      "128                6.0                8.0         ...            \n",
      "\n",
      "     Y1_P_TMCQ_SOOTHE  Y1_P_TMCQ_ASSERT  Y1_P_TMCQ_ATTFOCUS  Y1_P_TMCQ_LIP  \\\n",
      "376          3.125000          4.000000               3.250       4.125000   \n",
      "516          3.750000          3.375000               4.000       3.625000   \n",
      "270          2.750000          4.000000               2.500       3.714286   \n",
      "219          1.571429          4.250000               3.500       3.000000   \n",
      "371          4.750000          2.875000               4.875       3.500000   \n",
      "280          4.750000          4.500000               4.875       4.000000   \n",
      "144          3.750000          3.500000               4.125       3.875000   \n",
      "463          4.375000          3.500000               4.375       4.500000   \n",
      "418          2.375000          3.285714               1.750       4.375000   \n",
      "510          2.375000          4.500000               2.500       4.625000   \n",
      "526          3.125000          4.375000               1.500       3.500000   \n",
      "79           3.875000          1.875000               2.625       2.500000   \n",
      "572          4.625000          3.750000               1.750       3.000000   \n",
      "113          2.875000          3.000000               3.250       3.428571   \n",
      "479          3.875000          4.000000               2.875       3.500000   \n",
      "558          2.250000          2.000000               1.500       3.125000   \n",
      "429          3.875000          2.375000               4.375       3.625000   \n",
      "386          3.750000          4.000000               2.750       3.250000   \n",
      "391          3.500000          3.571429               4.625       4.000000   \n",
      "257          3.000000          4.000000               4.500       4.000000   \n",
      "319          3.750000          4.375000               2.625       4.400000   \n",
      "111          2.375000          4.125000               2.250       3.875000   \n",
      "414          3.875000          3.625000               4.875       4.000000   \n",
      "596          1.750000          3.875000               1.750       3.625000   \n",
      "6            4.125000          4.000000               3.250       4.000000   \n",
      "577          3.875000          3.500000               3.375       4.375000   \n",
      "467          4.250000          4.375000               4.250       3.250000   \n",
      "241          3.875000          3.625000               3.875       2.875000   \n",
      "222          4.000000          3.500000               4.125       3.750000   \n",
      "501          2.875000          3.250000               2.000       2.500000   \n",
      "..                ...               ...                 ...            ...   \n",
      "402          3.625000          3.250000               2.500       3.428571   \n",
      "274          3.500000          3.875000               3.625       2.833333   \n",
      "250          3.000000          3.142857               2.375       3.285714   \n",
      "63           2.500000          3.875000               1.375       3.166667   \n",
      "512          3.000000          4.000000               1.500       2.285714   \n",
      "356          3.750000          4.375000               1.500       2.714286   \n",
      "455          2.625000          3.500000               2.125       2.625000   \n",
      "532          4.625000          3.500000               4.125       3.125000   \n",
      "86           3.250000          4.125000               2.250       3.333333   \n",
      "96           3.250000          3.125000               2.625       4.000000   \n",
      "8            4.000000          3.250000               4.000       4.000000   \n",
      "210          3.250000          3.625000               2.375       3.375000   \n",
      "173          4.250000          3.375000               2.125       4.428571   \n",
      "118          2.375000          3.500000               1.750       3.833333   \n",
      "11           2.750000          4.750000               1.625       4.000000   \n",
      "462          2.500000          2.714286               1.375       2.500000   \n",
      "385          4.000000          3.000000               4.000       4.250000   \n",
      "269          4.500000          4.625000               4.000       4.000000   \n",
      "176          4.125000          3.125000               2.125       3.625000   \n",
      "206          4.500000          4.375000               1.625       3.750000   \n",
      "408          4.625000          3.750000               4.500       3.750000   \n",
      "193               NaN               NaN                 NaN            NaN   \n",
      "573          3.625000          4.375000               1.500       3.750000   \n",
      "46           4.125000          3.000000               4.750       3.875000   \n",
      "211          2.625000          3.375000               3.750       3.375000   \n",
      "600          2.500000          3.500000               2.375       2.250000   \n",
      "409          3.750000          4.250000               2.500       3.875000   \n",
      "580          2.875000          3.750000               2.625       3.375000   \n",
      "513          4.500000          3.000000               2.500       2.375000   \n",
      "128          4.125000          2.875000               4.000       4.125000   \n",
      "\n",
      "     Y1_P_TMCQ_PERCEPT  Y1_P_TMCQ_DISCOMF  Y1_P_TMCQ_OPENNESS  \\\n",
      "376           3.300000           2.600000            4.000000   \n",
      "516           3.888889           2.900000            4.111111   \n",
      "270           3.000000           2.800000            3.444444   \n",
      "219           3.300000           3.700000            4.666667   \n",
      "371           2.333333           1.700000            3.888889   \n",
      "280           3.400000           1.222222            4.333333   \n",
      "144           2.900000           2.500000            3.000000   \n",
      "463           4.100000           2.500000            4.666667   \n",
      "418           4.500000           4.000000            4.888889   \n",
      "510           3.400000           2.600000            4.444444   \n",
      "526           4.100000           2.500000            5.000000   \n",
      "79            2.100000           2.900000            2.444444   \n",
      "572           3.900000           3.200000            4.555556   \n",
      "113           2.400000           2.200000            3.666667   \n",
      "479           3.500000           1.800000            4.555556   \n",
      "558           2.400000           2.500000            3.444444   \n",
      "429           2.400000           2.700000            4.000000   \n",
      "386           3.600000           2.300000            4.333333   \n",
      "391           3.250000           2.200000            4.111111   \n",
      "257           3.100000           1.800000            4.444444   \n",
      "319           3.375000           3.100000            4.222222   \n",
      "111           3.100000           3.000000            4.777778   \n",
      "414           4.300000           2.400000            3.777778   \n",
      "596           4.400000           4.100000            4.888889   \n",
      "6             2.900000           2.900000            4.666667   \n",
      "577           3.900000           2.500000            4.777778   \n",
      "467           3.100000           2.300000            4.555556   \n",
      "241           3.200000           2.000000            3.222222   \n",
      "222           2.900000           1.900000            4.333333   \n",
      "501           3.100000           2.333333            2.666667   \n",
      "..                 ...                ...                 ...   \n",
      "402           3.500000           2.300000            4.000000   \n",
      "274           2.555556           1.700000            2.555556   \n",
      "250           3.857143           3.000000            3.000000   \n",
      "63            3.777778           4.000000            3.888889   \n",
      "512           2.444444           1.600000            3.000000   \n",
      "356           1.750000           1.800000            3.444444   \n",
      "455           3.100000           2.000000            3.000000   \n",
      "532           2.500000           2.100000            3.555556   \n",
      "86            3.800000           2.000000            3.250000   \n",
      "96            2.600000           2.300000            3.888889   \n",
      "8             3.000000           1.700000            3.888889   \n",
      "210           3.600000           2.900000            3.777778   \n",
      "173           4.666667           2.100000            5.000000   \n",
      "118           3.200000           2.300000            3.666667   \n",
      "11            3.200000           3.000000            3.888889   \n",
      "462           2.700000           2.000000            2.777778   \n",
      "385           3.500000           2.500000            4.222222   \n",
      "269           3.142857           1.777778            3.875000   \n",
      "176           4.375000           2.000000            4.444444   \n",
      "206           3.300000           1.700000            4.888889   \n",
      "408           3.600000           2.200000            4.555556   \n",
      "193                NaN                NaN                 NaN   \n",
      "573           3.400000           2.700000            3.888889   \n",
      "46            3.400000           1.500000            3.555556   \n",
      "211           3.000000           2.600000            3.375000   \n",
      "600           3.100000           2.800000            3.111111   \n",
      "409           4.500000           2.800000            4.888889   \n",
      "580           3.300000           2.100000            4.555556   \n",
      "513           3.000000           1.300000            4.666667   \n",
      "128           3.600000           2.600000            4.333333   \n",
      "\n",
      "     Y1_P_TMCQ_SURGENCY  Y1_P_TMCQ_EFFCONT  Y1_P_TMCQ_NEGAFFECT  \n",
      "376            3.445118           3.271667             2.758492  \n",
      "516            3.037710           3.713492             2.652222  \n",
      "270            4.207407           2.957143             2.792222  \n",
      "219            3.605387           3.200000             3.577460  \n",
      "371            2.973737           3.893333             1.562698  \n",
      "280            3.229630           4.272857             1.601429  \n",
      "144            3.455892           3.575000             2.610000  \n",
      "463            3.507744           4.075000             2.494206  \n",
      "418            3.972391           3.261667             4.000000  \n",
      "510            3.837037           3.126667             2.732619  \n",
      "526            3.607407           2.636667             3.262619  \n",
      "79             2.962290           2.771667             2.308810  \n",
      "572            3.119192           3.178333             3.114048  \n",
      "113            2.837037           2.962143             2.716111  \n",
      "479            4.672727           3.281667             2.098016  \n",
      "558            1.628956           2.420000             2.906825  \n",
      "429            2.413468           3.711667             2.474206  \n",
      "386            4.314815           2.970000             2.517619  \n",
      "391            3.748148           3.917857             2.484444  \n",
      "257            3.669360           3.640000             2.614286  \n",
      "319            3.707407           3.308333             2.435714  \n",
      "111            3.575758           2.920000             3.185317  \n",
      "414            3.707071           4.208333             2.307857  \n",
      "596            3.396296           2.838810             3.764603  \n",
      "6              4.569024           3.375000             2.810556  \n",
      "577            4.009428           3.723333             2.199921  \n",
      "467            3.788552           3.591667             2.217302  \n",
      "241            3.901684           3.496667             2.181508  \n",
      "222            2.737374           3.546667             2.179048  \n",
      "501            2.835690           2.733333             2.550079  \n",
      "..                  ...                ...                  ...  \n",
      "402            3.857912           3.152381             2.199127  \n",
      "274            3.369024           3.269444             1.971429  \n",
      "250            3.199327           2.923571             3.017778  \n",
      "63             3.644444           2.643889             3.978730  \n",
      "512            4.042424           2.154365             2.362540  \n",
      "356            3.855556           2.310165             1.905873  \n",
      "455            3.585859           2.843333             2.316587  \n",
      "532            3.309764           3.513333             1.571825  \n",
      "86             3.944444           2.905238             2.472857  \n",
      "96             3.548148           2.940000             2.498254  \n",
      "8              3.512458           3.730000             1.921905  \n",
      "210            3.686869           3.043333             2.809683  \n",
      "173            3.881481           3.545714             2.260476  \n",
      "118            3.581818           2.730000             2.677063  \n",
      "11             4.004040           2.916667             3.630000  \n",
      "462            2.825108           2.350714             2.831111  \n",
      "385            3.140741           3.841667             2.392381  \n",
      "269            3.985185           3.843571             1.875397  \n",
      "176            3.753535           3.241667             2.144524  \n",
      "206            4.720539           2.988333             1.927302  \n",
      "408            4.639731           3.870000             1.891429  \n",
      "193                 NaN                NaN                  NaN  \n",
      "573            2.916498           2.931667             2.825476  \n",
      "46             3.451852           4.000000             1.841667  \n",
      "211            3.523906           3.343333             2.852460  \n",
      "600            3.871380           2.708333             3.238730  \n",
      "409            4.701684           3.406667             2.601111  \n",
      "580            4.048485           2.861667             2.675476  \n",
      "513            4.203367           2.626667             1.737460  \n",
      "128            3.582492           3.805000             2.466746  \n",
      "\n",
      "[66 rows x 35 columns]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-ecfe82816843>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda2/envs/py36/lib/python3.6/site-packages/sklearn/cross_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[1;32m   1579\u001b[0m                                               \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1580\u001b[0m                                               fit_params)\n\u001b[0;32m-> 1581\u001b[0;31m                       for train, test in cv)\n\u001b[0m\u001b[1;32m   1582\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py36/lib/python3.6/site-packages/sklearn/cross_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, error_score)\u001b[0m\n\u001b[1;32m   1673\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1675\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1677\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py36/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0mThis\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \"\"\"\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py36/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    211\u001b[0m                 Xt, fitted_transformer = fit_transform_one_cached(\n\u001b[1;32m    212\u001b[0m                     \u001b[0mcloned_transformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m                     **fit_params_steps[name])\n\u001b[0m\u001b[1;32m    214\u001b[0m                 \u001b[0;31m# Replace the transformer of the step with the fitted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0;31m# transformer. This is necessary when loading the transformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/memory.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py36/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, weight, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m     \u001b[0;31m# if we have a weight for this transformer, multiply output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Galvanize/Capstone/Predicting_ADHD_Diagnoses/impute_transform.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomplete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py36/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__nonzero__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1119\u001b[0m         raise ValueError(\"The truth value of a {0} is ambiguous. \"\n\u001b[1;32m   1120\u001b[0m                          \u001b[0;34m\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                          .format(self.__class__.__name__))\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0m__bool__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "cross_val_score(clf, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
