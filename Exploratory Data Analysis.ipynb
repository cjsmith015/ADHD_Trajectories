{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "from model_metrics import *\n",
    "from fancyimpute import *\n",
    "import pickle\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_data = pd.read_csv('data/Christie_diagnosis_20180118.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Imputation Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For information on algorithms, see [fancyimpute](https://pypi.python.org/pypi/fancyimpute)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make all the solver objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "KNN_solver = KNN(k=5)\n",
    "softimpute_solver = SoftImpute()\n",
    "MICE_solver = MICE()\n",
    "simple_solver = SimpleFill()\n",
    "iterativeSVD_solver = IterativeSVD()\n",
    "matrixfactorization_solver = MatrixFactorization()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dataframe from the complete data in `train_data`. Then, randomly insert some NaNs for MSE testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop NaNs\n",
    "complete_data = train_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop DX and DXSUB\n",
    "complete_data.drop(columns=['DX', 'DXSUB'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Randomly insert NaNs\n",
    "nan_inserted_data = complete_data.copy()\n",
    "import random\n",
    "ix = [(row, col) for row in range(complete_data.shape[0]) for col in range(complete_data.shape[1])]\n",
    "for row, col in random.sample(ix, int(round(.1*len(ix)))):\n",
    "    nan_inserted_data.iat[row, col] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "missing_mask = nan_inserted_data.isna().any(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete those missing dataframes with the various solvers!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_imputation(solver, df):\n",
    "    \"\"\"Impute the data using imputation methods\"\"\"\n",
    "    impute_data = df.values\n",
    "    data_index = df.index\n",
    "    data_cols = df.columns\n",
    "\n",
    "    impute_data_filled = solver.complete(impute_data)\n",
    "    impute_df = pd.DataFrame(impute_data_filled, index=data_index, columns=data_cols)\n",
    "    return impute_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "KNN_df = test_imputation(KNN_solver, nan_inserted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "softimpute_df = test_imputation(softimpute_solver, nan_inserted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MICE_df = test_imputation(MICE_solver, nan_inserted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "simple_df = test_imputation(simple_solver, nan_inserted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iterative_df = test_imputation(iterativeSVD_solver, nan_inserted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "matrixfact_df = test_imputation(matrixfactorization_solver, nan_inserted_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now cast as ints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "solver_list = [KNN_df, softimpute_df, MICE_df,\n",
    "               simple_df, iterative_df, matrixfact_df]\n",
    "solver_names = ['KNN', 'SoftImpute', 'MICE', 'SimpleFill',\n",
    "                   'IterativeSVD', 'MatrixFactorization']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "KNN_df_round = KNN_df.copy()\n",
    "softimpute_df_round = softimpute_df.copy()\n",
    "MICE_df_round = MICE_df.copy()\n",
    "simple_df_round = simple_df.copy()\n",
    "iterative_df_round = iterative_df.copy()\n",
    "matrixfact_df_round = matrixfact_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "round_list = [KNN_df_round, softimpute_df_round, MICE_df_round,\n",
    "              simple_df_round, iterative_df_round, matrixfact_df_round]\n",
    "round_names = ['KNN_round', 'SoftImpute_round', 'MICE_round',\n",
    "            'SimpleFill_round', 'IterativeSVD_round', 'MatrixFact_round']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "int_cols = ['SSBK_NUMCOMPLETE_Y1', 'SSFD_NUMCOMPLETE_Y1',\n",
    "            'Y1_CLWRD_COND1', 'Y1_CLWRD_COND2', 'Y1_DIGITS_BKWD_RS',\n",
    "            'Y1_DIGITS_FRWD_RS', 'Y1_TRAILS_COND2', 'Y1_TRAILS_COND3']\n",
    "for df in round_list:\n",
    "    for col in int_cols:\n",
    "        df[col] = df[col].astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create MSEs for each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_df_list = solver_list + round_list\n",
    "total_df_names = solver_names + round_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mse_df = pd.DataFrame(index=total_df_names, columns=complete_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "for df, name in zip(total_df_list, total_df_names):\n",
    "    mse = ((df[missing_mask] - complete_data[missing_mask]) ** 2).mean()\n",
    "    mse_df.loc[name] = mse\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mse_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which method has the lowest MSEs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write `true` for minimums in each col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mse_df_bool = mse_df.copy()\n",
    "for col in mse_df.columns:\n",
    "    mse_df_bool[col] = (mse_df_bool[col] == np.min(mse_df_bool[col]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mse_df_bool.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "int_cols_nodx = ['SSBK_NUMCOMPLETE_Y1',\n",
    " 'SSFD_NUMCOMPLETE_Y1',\n",
    " 'Y1_CLWRD_COND1',\n",
    " 'Y1_CLWRD_COND2',\n",
    " 'Y1_DIGITS_BKWD_RS',\n",
    " 'Y1_DIGITS_FRWD_RS',\n",
    " 'Y1_TRAILS_COND2',\n",
    " 'Y1_TRAILS_COND3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mse_df_bool[int_cols_nodx].sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, MICE seems to do the best for columns that are technically integers (3 out of 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like MatrixFactorization is the best option. (out of 38 cols, 24 went to MatrixFactorization for the lowest MSE)\n",
    "\n",
    "Rounding does not improve the MSE. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing for leaky data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I had really high accuracy on my first logistic regression model (91% test accuracy on smaller train/test split, and 92% accuracy on cross-validated log models).\n",
    "\n",
    "So, I want to investigate if I have any leaky data columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = train_data.drop(columns=['DX','DXSUB'])\n",
    "y_train = train_data['DX']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_small, X_test_small, y_train_small, y_test_small = train_test_split(\n",
    "                    X_train, y_train, test_size=0.2, random_state=56)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy_list = []\n",
    "for col in X_train_small.columns:\n",
    "    # Drop the column\n",
    "    X_train_dataset = X_train_small.drop(columns=col).values\n",
    "    X_test_dataset = X_test_small.drop(columns=col).values\n",
    "    \n",
    "    # Impute the data if missing numbers\n",
    "    if np.sum(np.isnan(X_train_dataset)) > 0:\n",
    "        X_train_final = impute_data(X_train_dataset)\n",
    "    else:\n",
    "        X_train_final = X_train_dataset.copy()\n",
    "\n",
    "    if np.sum(np.isnan(X_test_dataset)) > 0:\n",
    "        X_test_final = impute_data(X_test_dataset)\n",
    "    else:\n",
    "        X_test_final = X_test_dataset.copy()\n",
    "        \n",
    "    # Fit model\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train_final, y_train_small)\n",
    "    \n",
    "    # Score model\n",
    "    accuracy = model.score(y_test_final, y_test_small)\n",
    "    accuracy_list.append((col, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy_list\n",
    "for col, acc in accuracy_list:\n",
    "    print(\"Accuracy removing {}: \\t \\t {:2.2f}\".format(col, acc).expandtabs(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_small_impute = impute_data(X_train_small.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logreg.fit(X_train_small_impute, y_train_small.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logreg.score(impute_data(X_test_small.values), y_test_small.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like there aren't any leaky variables. I just have high accuracy.\n",
    "\n",
    "This makes sense - the lab wouldn't administer tests or behavioral questionnaires that don't have something to do with ADHD. So a straight logistical model is pretty accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going forward, I want to do a few things:\n",
    "\n",
    "- How high can I get the accuracy? Test out a few different models (RF, Gradient Boosting)\n",
    "- What's the spread of the predicted probas like?\n",
    "- Test out on DXSUB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Model Metrics Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_DX = train_data.drop(columns=['DX','DXSUB'])\n",
    "y_train_DX = train_data['DX']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_small, X_test_small, y_train_small, y_test_small = train_test_split(\n",
    "                    X_train_DX, y_train_DX, test_size=0.2, random_state=56)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logmod = LogisticRegression()\n",
    "logmod.fit(impute_data(X_train_small.values), y_train_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_prob_dx = logmod.predict_proba(impute_data(X_test_small.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prob_dx = logmod.predict(impute_data(X_test_small.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(pred_prob_dx[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_jitter(data, jitter=0.1):\n",
    "    return np.random.uniform(-jitter, jitter, size=data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,2))\n",
    "\n",
    "_ = ax.scatter(pred_prob_dx[:,0], make_jitter(pred_prob_dx[:,0]), c=np.vectorize(dx_dict.get)(y_test_small),\n",
    "           s=40, alpha=0.5)\n",
    "_ = ax.set_xlim(0,1)\n",
    "_ = ax.set_title('Predicted Probability of Positive vs Negative Classes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test_small, prob_dx, pos_label=3, drop_intermediate=False)\n",
    "roc_auc = auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(fpr, tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I created logistic regression, random forest, and gradient boosting models. I want to see the MSE and accuracy on train/test, cross-validated (k-fold=10), when predicting DX, and when predicting DXSUB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train_data = pd.read_csv('data/train_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%%capture\n",
    "#classifier_metrics = run_classifiers(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#with open('classifier_metrics.pkl', 'wb') as f:\n",
    "    #pickle.dump(classifier_metrics, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classification_metrics = pickle.load(open(\"classifier_metrics.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#[clf][pred][metric][train/test]\n",
    "# Logistic Regression\n",
    "lr_dx_mse_train = np.mean(classification_metrics[0][0][0][0])\n",
    "lr_dx_mse_test = np.mean(classification_metrics[0][0][0][1])\n",
    "lr_dx_acc_train = np.mean(classification_metrics[0][0][1][0])\n",
    "lr_dx_acc_test = np.mean(classification_metrics[0][0][1][1])\n",
    "\n",
    "lr_dxsub_mse_train = np.mean(classification_metrics[0][1][0][0])\n",
    "lr_dxsub_mse_test = np.mean(classification_metrics[0][1][0][1])\n",
    "lr_dxsub_acc_train = np.mean(classification_metrics[0][1][1][0])\n",
    "lr_dxsub_acc_test = np.mean(classification_metrics[0][1][1][1])\n",
    "\n",
    "# Random Forest\n",
    "rf_dx_mse_train = np.mean(classification_metrics[1][0][0][0])\n",
    "rf_dx_mse_test = np.mean(classification_metrics[1][0][0][1])\n",
    "rf_dx_acc_train = np.mean(classification_metrics[1][0][1][0])\n",
    "rf_dx_acc_test = np.mean(classification_metrics[1][0][1][1])\n",
    "\n",
    "rf_dxsub_mse_train = np.mean(classification_metrics[1][1][0][0])\n",
    "rf_dxsub_mse_test = np.mean(classification_metrics[1][1][0][1])\n",
    "rf_dxsub_acc_train = np.mean(classification_metrics[1][1][1][0])\n",
    "rf_dxsub_acc_test = np.mean(classification_metrics[1][1][1][1])\n",
    "\n",
    "# Gradient Boosting\n",
    "gb_dx_mse_train = np.mean(classification_metrics[2][0][0][0])\n",
    "gb_dx_mse_test = np.mean(classification_metrics[2][0][0][1])\n",
    "gb_dx_acc_train = np.mean(classification_metrics[2][0][1][0])\n",
    "gb_dx_acc_test = np.mean(classification_metrics[2][0][1][1])\n",
    "\n",
    "gb_dxsub_mse_train = np.mean(classification_metrics[2][1][0][0])\n",
    "gb_dxsub_mse_test = np.mean(classification_metrics[2][1][0][1])\n",
    "gb_dxsub_acc_train = np.mean(classification_metrics[2][1][1][0])\n",
    "gb_dxsub_acc_test = np.mean(classification_metrics[2][1][1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make dataframes\n",
    "metrics_dx_dict = {'DX_acc_train': [lr_dx_acc_train, rf_dx_acc_train, gb_dx_acc_train],\n",
    "                   'DX_acc_test': [lr_dx_acc_test, rf_dx_acc_test, gb_dx_acc_test],\n",
    "                   'DX_mse_train': [lr_dx_mse_train, rf_dx_mse_train, gb_dx_mse_train],\n",
    "                   'DX_mse_test': [lr_dx_mse_test, rf_dx_mse_test, gb_dx_mse_test]}\n",
    "\n",
    "metrics_DX = pd.DataFrame(data=metrics_dx_dict,\n",
    "                          columns=['DX_acc_train', 'DX_acc_test', 'DX_mse_train', 'DX_mse_test'],\n",
    "                          index=['LogReg', 'RandomForest', 'GradBoost'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metrics_dxsub_dict = {'DXSUB_acc_train': [lr_dxsub_acc_train, rf_dxsub_acc_train, gb_dxsub_acc_train],\n",
    "                   'DXSUB_acc_test': [lr_dxsub_acc_test, rf_dxsub_acc_test, gb_dxsub_acc_test],\n",
    "                   'DXSUB_mse_train': [lr_dxsub_mse_train, rf_dxsub_mse_train, gb_dxsub_mse_train],\n",
    "                   'DXSUB_mse_test': [lr_dxsub_mse_test, rf_dxsub_mse_test, gb_dxsub_mse_test]}\n",
    "\n",
    "metrics_DXSUB = pd.DataFrame(data=metrics_dxsub_dict,\n",
    "                             columns=['DXSUB_acc_train', 'DXSUB_acc_test', 'DXSUB_mse_train', 'DXSUB_mse_test'],\n",
    "                             index=['LogReg', 'RandomForest', 'GradBoost'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metrics_DX.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metrics_DXSUB.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neuropsych vs TMCQ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I've evaluated models on all the data, I want to check out what accuracy and mse looks like for models run JUST on neuropsych, and JUST on TMCQ.\n",
    "\n",
    "I'll use the same exact procedure as above, just with different X matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('data/train_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_TMCQ = train_data[['Y1_P_TMCQ_ACTIVCONT', 'Y1_P_TMCQ_ACTIVITY', 'Y1_P_TMCQ_AFFIL',\n",
    "       'Y1_P_TMCQ_ANGER', 'Y1_P_TMCQ_FEAR', 'Y1_P_TMCQ_HIP',\n",
    "       'Y1_P_TMCQ_IMPULS', 'Y1_P_TMCQ_INHIBIT', 'Y1_P_TMCQ_SAD',\n",
    "       'Y1_P_TMCQ_SHY', 'Y1_P_TMCQ_SOOTHE', 'Y1_P_TMCQ_ASSERT',\n",
    "       'Y1_P_TMCQ_ATTFOCUS', 'Y1_P_TMCQ_LIP', 'Y1_P_TMCQ_PERCEPT',\n",
    "       'Y1_P_TMCQ_DISCOMF', 'Y1_P_TMCQ_OPENNESS', 'Y1_P_TMCQ_SURGENCY',\n",
    "       'Y1_P_TMCQ_EFFCONT', 'Y1_P_TMCQ_NEGAFFECT']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_TMCQ.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_neuro = train_data[['STOP_SSRTAVE_Y1', 'DPRIME1_Y1', 'DPRIME2_Y1', 'SSBK_NUMCOMPLETE_Y1',\n",
    "       'SSFD_NUMCOMPLETE_Y1', 'V_Y1', 'Y1_CLWRD_COND1', 'Y1_CLWRD_COND2',\n",
    "       'Y1_DIGITS_BKWD_RS', 'Y1_DIGITS_FRWD_RS', 'Y1_TRAILS_COND2',\n",
    "       'Y1_TRAILS_COND3', 'CW_RES', 'TR_RES', 'Y1_TAP_SD_TOT_CLOCK']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_all = train_data[['DX', 'DXSUB']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Must drop subjects where ALL data is missing, due to matrix factorixation imputation\n",
    "X_TMCQ_nonull = X_TMCQ.dropna(how='all')\n",
    "X_neuro_nonull = X_neuro.dropna(how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "TMCQ_dx, TMCQ_dxsub = run_classifiers(X_TMCQ_nonull, y_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TMCQ_dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TMCQ_dxsub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "neuro_dx, neuro_dxsub = run_classifiers(X_neuro_nonull, y_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neuro_dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neuro_dxsub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Pipeline for CV "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I just remembered that sklearn.pipeline is a thing.\n",
    "So, I'm going to build that so cross-validation and multiple metrics are easier!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From sklearn:\n",
    "```\n",
    "from sklearn.pipeline import make_pipeline\n",
    "clf = make_pipeline(preprocessing.StandardScaler(), svm.SVC(C=1))\n",
    "cross_val_score(clf, iris.data, iris.target, cv=cv)\n",
    "...                                                 \n",
    "array([ 0.97...,  0.93...,  0.95...])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_validate\n",
    "from fancyimpute import MICE\n",
    "from impute_transform import ImputeTransform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('data/train_data.csv')\n",
    "train_data_small = train_data.sample(n=100)\n",
    "X = train_data_small.drop(columns=['DX','DXSUB'])\n",
    "y = train_data_small['DX'].map({3:1,1:0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf = make_pipeline(ImputeTransform(strategy=MatrixFactorization()), LogisticRegression(random_state=56))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scoring = ['accuracy', 'roc_auc', 'neg_log_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores = cross_validate(clf, X, y, scoring=scoring, cv=2, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Thoughts for the day\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My brain is pretty fried, so I'm gonna call it a night.\n",
    "\n",
    "But here's next steps for tomorrow:\n",
    "- Get this cross_validate function working for log_reg, rf, gb, and xgb\n",
    "- Get this cross_validate function working for DXSUB\n",
    " - cause of the multiclass problem and all that\n",
    "- Explore TMCQ and neuropsych more\n",
    " - The metrics were quite bad on these! And logistic regression actually performed better test-wise than RF and GB!\n",
    "- Discuss next steps with Matt\n",
    " - Clustering ideas\n",
    " - How to approach hyperparam tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clustering Ideas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Subtyping ADHD Using Tempermant Dimensions](https://jamanetwork.com/journals/jamapsychiatry/fullarticle/1885709)\n",
    "\n",
    "The above is a paper written by my boss (Dr. Karalunas) that utilized community detection analysis on the Temperment in Middle Childhood Questionnaire (TMCQ).\n",
    "They had 437 children and used the TMCQ from year 1. \n",
    "They specifically used the [Fast Greedy algorithm](https://arxiv.org/abs/cond-mat/0408187) and found 3 profiles of children, which they labeled as \"mild\", \"surgent\", and \"irritable\".\n",
    "\n",
    "I was thinking of trying to replicate this analysis on the full 901 dataset ([community detection in python](https://yoyoinwanderland.github.io/2017/08/08/Community-Detection-in-Python/)).\n",
    "Then, I was thinking of trying different clustering algorithms to see if the same profiles seem to exist.\n",
    "\n",
    "It'd basically be a study in reproducability.\n",
    "\n",
    "They used physiological and MRI data to externally validate these profiles, which I don't really have. But I might be able to glean something interesting from the neuropsych data? Maybe? IDK. Focus on \"are the profiles there\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Pipeline Continuing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to test the following models:\n",
    "- Logistic Regression\n",
    "- Random Forest\n",
    "- Gradient Boosting\n",
    "- XGBoost\n",
    "\n",
    "With the following metrics:\n",
    "- ROC AUC\n",
    "- Accuracy\n",
    "- Log Loss\n",
    "\n",
    "On the following data:\n",
    "- DX\n",
    "- DXSUB\n",
    "- Neuropsych\n",
    "- TMCQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import make_scorer, accuracy_score, log_loss\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_validate\n",
    "from impute_transform import ImputeTransform\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the models for real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('data/train_data.csv')\n",
    "X = train_data.drop(columns=['DX','DXSUB'])\n",
    "y = train_data['DX'].map({3:1,1:0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_clf = make_pipeline(ImputeTransform(strategy=MatrixFactorization()),\n",
    "                        LogisticRegression(random_state=56))\n",
    "\n",
    "rf_clf = make_pipeline(ImputeTransform(strategy=MatrixFactorization()),\n",
    "                       RandomForestClassifier(n_jobs=-1, random_state=56))\n",
    "\n",
    "gb_clf = make_pipeline(ImputeTransform(strategy=MatrixFactorization()),\n",
    "                       GradientBoostingClassifier(random_state=56))\n",
    "\n",
    "xgb_clf = make_pipeline(ImputeTransform(strategy=MatrixFactorization()),\n",
    "                        XGBClassifier(max_depth=3, learning_rate=0.1,\n",
    "                        random_state=56))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scoring = ['accuracy', 'roc_auc', 'neg_log_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier_list = [log_reg_clf, rf_clf, gb_clf, xgb_clf]\n",
    "classifier_name = ['LogReg', 'RandomForest', 'GradientBoosting', 'XGB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "classifier_metrics = {}\n",
    "for clf, name in zip(classifier_list, classifier_name):\n",
    "    scores = cross_validate(clf, X, y, scoring=scoring, cv=5, return_train_score=False)\n",
    "    classifier_metrics[name] = scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'GradientBoosting': {'fit_time': array([ 5.61365485,  5.96402812,  5.96304774,  6.71043992,  5.83259368]),\n",
       "  'score_time': array([  8.31407118,   5.76415157,  10.13945103,  10.34139943,   7.99768829]),\n",
       "  'test_accuracy': array([ 0.91735537,  0.90909091,  0.94214876,  0.95      ,  0.94166667]),\n",
       "  'test_neg_log_loss': array([-0.25958926, -0.28074731, -0.22154339, -0.15010377, -0.21449213]),\n",
       "  'test_roc_auc': array([ 0.95877193,  0.95467836,  0.96432749,  0.9763756 ,  0.97159091])},\n",
       " 'LogReg': {'fit_time': array([ 3.91597986,  4.13191342,  3.81056094,  4.5563941 ,  4.3751905 ]),\n",
       "  'score_time': array([ 2.40666628,  5.38883543,  2.07561421,  5.07782388,  4.31213188]),\n",
       "  'test_accuracy': array([ 0.8677686 ,  0.90909091,  0.91735537,  0.95      ,  0.9       ]),\n",
       "  'test_neg_log_loss': array([-0.303425  , -0.20680224, -0.17379683, -0.12765787, -0.24626423]),\n",
       "  'test_roc_auc': array([ 0.94678363,  0.96783626,  0.97807018,  0.99162679,  0.96979665])},\n",
       " 'RandomForest': {'fit_time': array([ 5.14483809,  4.96018982,  4.71552038,  5.55765605,  5.67883229]),\n",
       "  'score_time': array([ 5.05931592,  3.93036222,  4.36761403,  7.26334238,  6.65323687]),\n",
       "  'test_accuracy': array([ 0.95041322,  0.88429752,  0.9338843 ,  0.94166667,  0.9       ]),\n",
       "  'test_neg_log_loss': array([-0.73171012, -0.80447991, -0.19754602, -0.44814015, -0.50018946]),\n",
       "  'test_roc_auc': array([ 0.96388889,  0.93040936,  0.96885965,  0.96889952,  0.96680622])},\n",
       " 'XGB': {'fit_time': array([ 5.92196536,  6.61412716,  6.22723341,  6.76755476,  7.08812499]),\n",
       "  'score_time': array([  8.63678384,  11.09677935,   9.95250583,   9.61867094,   9.36961031]),\n",
       "  'test_accuracy': array([ 0.91735537,  0.90909091,  0.91735537,  0.95      ,  0.90833333]),\n",
       "  'test_neg_log_loss': array([-0.23991629, -0.25074098, -0.21851178, -0.1299907 , -0.22935304]),\n",
       "  'test_roc_auc': array([ 0.95964912,  0.96929825,  0.97719298,  0.98624402,  0.9742823 ])}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for classifier, dictionary in classifier_metrics.items():\n",
    "    for metric, score in classifier_metrics[classifier].items():\n",
    "        classifier_metrics[classifier][metric] = np.mean(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "name_of_metrics = ['fit_time', 'score_time', 'test_accuracy',\n",
    "                   'test_neg_log_loss', 'test_roc_auc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metrics_df = pd.DataFrame(data=None,\n",
    "                          index=classifier_name,\n",
    "                          columns=name_of_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for clf in classifier_name:\n",
    "    for metric in name_of_metrics:\n",
    "        metrics_df[metric].loc[clf] = classifier_metrics[clf][metric]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_neg_log_loss</th>\n",
       "      <th>test_roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogReg</th>\n",
       "      <td>4.15801</td>\n",
       "      <td>3.85221</td>\n",
       "      <td>0.908843</td>\n",
       "      <td>-0.211589</td>\n",
       "      <td>0.970823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>5.21141</td>\n",
       "      <td>5.45477</td>\n",
       "      <td>0.922052</td>\n",
       "      <td>-0.536413</td>\n",
       "      <td>0.959773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoosting</th>\n",
       "      <td>6.01675</td>\n",
       "      <td>8.51135</td>\n",
       "      <td>0.932052</td>\n",
       "      <td>-0.225295</td>\n",
       "      <td>0.965149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGB</th>\n",
       "      <td>6.5238</td>\n",
       "      <td>9.73487</td>\n",
       "      <td>0.920427</td>\n",
       "      <td>-0.213703</td>\n",
       "      <td>0.973333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 fit_time score_time test_accuracy test_neg_log_loss  \\\n",
       "LogReg            4.15801    3.85221      0.908843         -0.211589   \n",
       "RandomForest      5.21141    5.45477      0.922052         -0.536413   \n",
       "GradientBoosting  6.01675    8.51135      0.932052         -0.225295   \n",
       "XGB                6.5238    9.73487      0.920427         -0.213703   \n",
       "\n",
       "                 test_roc_auc  \n",
       "LogReg               0.970823  \n",
       "RandomForest         0.959773  \n",
       "GradientBoosting     0.965149  \n",
       "XGB                  0.973333  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# testing on holdout to see if its somewhat similar or\n",
    "# super off like it was for tmcq...\n",
    "holdout_data = pd.read_csv('data/holdout_data.csv')\n",
    "X_test = holdout_data.drop(columns=['DX','DXSUB'])\n",
    "y_test = holdout_data['DX'].map({3:1,1:0})\n",
    "# yep, it worked there..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGB and LogReg have the best AUC scores, and log_loss scores. Even though GB had the highest test accuracy, I think XGB and LogReg are the models to explore."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I also want to run this on Neuropsych and TMCQ data. It seemed like last time, RF and GB overfit - but XGBoost has regularization so this might mediate that problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_TMCQ = train_data[['Y1_P_TMCQ_ACTIVCONT', 'Y1_P_TMCQ_ACTIVITY', 'Y1_P_TMCQ_AFFIL',\n",
    "       'Y1_P_TMCQ_ANGER', 'Y1_P_TMCQ_FEAR', 'Y1_P_TMCQ_HIP',\n",
    "       'Y1_P_TMCQ_IMPULS', 'Y1_P_TMCQ_INHIBIT', 'Y1_P_TMCQ_SAD',\n",
    "       'Y1_P_TMCQ_SHY', 'Y1_P_TMCQ_SOOTHE', 'Y1_P_TMCQ_ASSERT',\n",
    "       'Y1_P_TMCQ_ATTFOCUS', 'Y1_P_TMCQ_LIP', 'Y1_P_TMCQ_PERCEPT',\n",
    "       'Y1_P_TMCQ_DISCOMF', 'Y1_P_TMCQ_OPENNESS', 'Y1_P_TMCQ_SURGENCY',\n",
    "       'Y1_P_TMCQ_EFFCONT', 'Y1_P_TMCQ_NEGAFFECT']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_TMCQ_nonull = X_TMCQ[X_TMCQ.isnull().sum(axis=1) == 0]\n",
    "y_TMCQ_nonull = y[X_TMCQ.isnull().sum(axis=1) == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Don't need imputation for TMCQ because I removed NaNs\n",
    "log_reg_clf = LogisticRegression(random_state=56)\n",
    "\n",
    "rf_clf = RandomForestClassifier(n_jobs=-1, random_state=56)\n",
    "\n",
    "gb_clf = GradientBoostingClassifier(random_state=56)\n",
    "\n",
    "xgb_clf = XGBClassifier(max_depth=3, learning_rate=0.1,\n",
    "                        random_state=56)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier_list = [log_reg_clf, rf_clf, gb_clf, xgb_clf]\n",
    "classifier_name = ['LogReg', 'RandomForest', 'GradientBoosting', 'XGB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "classifier_metrics_TMCQ = {}\n",
    "for clf, name in zip(classifier_list, classifier_name):\n",
    "    scores = cross_validate(clf, X_TMCQ_nonull, y_TMCQ_nonull, scoring=scoring, cv=5, return_train_score=True)\n",
    "    classifier_metrics_TMCQ[name] = scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for classifier, dictionary in classifier_metrics_TMCQ.items():\n",
    "    for metric, score in classifier_metrics_TMCQ[classifier].items():\n",
    "        classifier_metrics_TMCQ[classifier][metric] = np.mean(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "name_of_metrics = ['fit_time', 'score_time', 'test_accuracy',\n",
    "                   'test_neg_log_loss', 'test_roc_auc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df_TMCQ = pd.DataFrame(data=None,\n",
    "                          index=classifier_name,\n",
    "                          columns=name_of_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for clf in classifier_name:\n",
    "    for metric in name_of_metrics:\n",
    "        metrics_df_TMCQ[metric].loc[clf] = classifier_metrics_TMCQ[clf][metric]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_neg_log_loss</th>\n",
       "      <th>test_roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogReg</th>\n",
       "      <td>0.00237722</td>\n",
       "      <td>0.00162859</td>\n",
       "      <td>0.927743</td>\n",
       "      <td>-0.178276</td>\n",
       "      <td>0.978986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>0.112036</td>\n",
       "      <td>0.318826</td>\n",
       "      <td>0.92941</td>\n",
       "      <td>-0.632891</td>\n",
       "      <td>0.956898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoosting</th>\n",
       "      <td>0.0756029</td>\n",
       "      <td>0.00187788</td>\n",
       "      <td>0.926091</td>\n",
       "      <td>-0.218861</td>\n",
       "      <td>0.969757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGB</th>\n",
       "      <td>0.0295064</td>\n",
       "      <td>0.00283685</td>\n",
       "      <td>0.927715</td>\n",
       "      <td>-0.207033</td>\n",
       "      <td>0.971983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    fit_time  score_time test_accuracy test_neg_log_loss  \\\n",
       "LogReg            0.00237722  0.00162859      0.927743         -0.178276   \n",
       "RandomForest        0.112036    0.318826       0.92941         -0.632891   \n",
       "GradientBoosting   0.0756029  0.00187788      0.926091         -0.218861   \n",
       "XGB                0.0295064  0.00283685      0.927715         -0.207033   \n",
       "\n",
       "                 test_roc_auc  \n",
       "LogReg               0.978986  \n",
       "RandomForest         0.956898  \n",
       "GradientBoosting     0.969757  \n",
       "XGB                  0.971983  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df_TMCQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# testing on holdout to see if its somewhat similar\n",
    "X_test_TMCQ = holdout_data[['Y1_P_TMCQ_ACTIVCONT', 'Y1_P_TMCQ_ACTIVITY', 'Y1_P_TMCQ_AFFIL',\n",
    "       'Y1_P_TMCQ_ANGER', 'Y1_P_TMCQ_FEAR', 'Y1_P_TMCQ_HIP',\n",
    "       'Y1_P_TMCQ_IMPULS', 'Y1_P_TMCQ_INHIBIT', 'Y1_P_TMCQ_SAD',\n",
    "       'Y1_P_TMCQ_SHY', 'Y1_P_TMCQ_SOOTHE', 'Y1_P_TMCQ_ASSERT',\n",
    "       'Y1_P_TMCQ_ATTFOCUS', 'Y1_P_TMCQ_LIP', 'Y1_P_TMCQ_PERCEPT',\n",
    "       'Y1_P_TMCQ_DISCOMF', 'Y1_P_TMCQ_OPENNESS', 'Y1_P_TMCQ_SURGENCY',\n",
    "       'Y1_P_TMCQ_EFFCONT', 'Y1_P_TMCQ_NEGAFFECT']]\n",
    "y_test_TMCQ = holdout_data['DX'].map({3:1,1:0})\n",
    "\n",
    "X_test_TMCQ_nonull = X_test_TMCQ[X_test_TMCQ.isnull().sum(axis=1) == 0]\n",
    "y_test_TMCQ_nonull = y_test[X_test_TMCQ.isnull().sum(axis=1) == 0]\n",
    "# also get similar results! yay!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
